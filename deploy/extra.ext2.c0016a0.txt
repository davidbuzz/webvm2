re_sfmt += s
        self.instance_ofs = struct.calcsize(pre_sfmt)
        (ifmt,) = self.format[instance_idx]
        self.instance_len = struct.calcsize(ifmt)

    def set_unit_ids(self, unit_ids, unit_lookup):
        '''set unit IDs string from FMTU'''
        if unit_ids is None:
            return
        # Does this unit string define an instance field?
        instance_idx = unit_ids.find('#')
        if instance_idx != -1:
            self.set_instance_field(instance_idx)
        # Build the units array from the IDs
        self.units = [""]*len(self.columns)
        for i in range(len(self.columns)):
            if i < len(unit_ids):
                if unit_ids[i] in unit_lookup:
                    self.units[i] = unit_lookup[unit_ids[i]]

    def set_mult_ids(self, mult_ids, mult_lookup):
        '''set mult IDs string from FMTU'''
        # Update the units based on the multiplier
        for i in range(len(self.units)):
            # If the format has its own multiplier, do not adjust the unit,
            # and if no unit is specified there is nothing to adjust
            if self.msg_mults[i] is not None or self.units[i] == "":
                continue
            # Get the unit multiplier from the lookup table
            if mult_ids[i] in mult_lookup:
                unitmult = mult_lookup[mult_ids[i]]
                # Combine the multipler and unit to derive the real unit
                if unitmult in MULT_TO_PREFIX:
                    self.units[i] = MULT_TO_PREFIX[unitmult]+self.units[i]
                else:
                    self.units[i] = "%.4g %s" % (unitmult, self.units[i])

    def get_unit(self, col):
        '''Return the unit for the specified field'''
        if self.units is None:
            return ""
        else:
            idx = self.colhash[col]
            return self.units[idx]

    def __str__(self):
        return ("DFFormat(%s,%s,%s,%s)" %
                (self.type, self.name, self.format, self.columns))

# Swiped into mavgen_python.py
def to_string(s):
    '''desperate attempt to convert a string regardless of what garbage we get'''
    if isinstance(s, str):
        return s
    if sys.version_info[0] == 2:
        # In python2 we want to return unicode for passed in unicode
        return s
    return s.decode(errors="backslashreplace")

def null_term(string):
    '''null terminate a string'''
    if isinstance(string, bytes):
        string = to_string(string)
    idx = string.find("\0")
    if idx != -1:
        string = string[:idx]
    return string


class DFMessage(object):
    def __init__(self, fmt, elements, apply_multiplier, parent):
        self.fmt = fmt
        self._elements = elements
        self._apply_multiplier = apply_multiplier
        self._fieldnames = fmt.columns
        self._parent = parent

    def to_dict(self):
        d = {'mavpackettype': self.fmt.name}

        for field in self._fieldnames:
            d[field] = self.__getattr__(field)

        return d

    def __getattr__(self, field):
        '''override field getter'''
        try:
            i = self.fmt.colhash[field]
        except Exception:
            raise AttributeError(field)
        if self.fmt.msg_fmts[i] == 'Z' and self.fmt.name == 'FILE':
            # special case for FILE contens as bytes
            return self._elements[i]
        if isinstance(self._elements[i], bytes):
            try:
                v = self._elements[i].decode("utf-8")
            except UnicodeDecodeError:
                # try western europe
                v = self._elements[i].decode("ISO-8859-1")
        else:
            v = self._elements[i]
        if self.fmt.format[i] == 'a':
            pass
        elif self.fmt.format[i] != 'M' or self._apply_multiplier:
            v = self.fmt.msg_types[i](v)
        if self.fmt.msg_types[i] == str:
            v = null_term(v)
        if self.fmt.msg_mults[i] is not None and self._apply_multiplier:
            # For reasons relating to floating point accuracy, you get a more
            # accurate result by dividing by 1e2 or 1e7 than multiplying by
            # 1e-2 or 1e-7
            if self.fmt.msg_mults[i] > 0.0 and self.fmt.msg_mults[i] < 1.0:
                divisor = 1/self.fmt.msg_mults[i]
                v /= divisor
            else:
                v *= self.fmt.msg_mults[i]
        return v

    def __setattr__(self, field, value):
        '''override field setter'''
        if not field[0].isupper() or not field in self.fmt.colhash:
            super(DFMessage,self).__setattr__(field, value)
        else:
            i = self.fmt.colhash[field]
            if self.fmt.msg_mults[i] is not None and self._apply_multiplier:
                value /= self.fmt.msg_mults[i]
            self._elements[i] = value

    def get_type(self):
        return self.fmt.name

    def __str__(self):
        is_py3 = sys.version_info >= (3,0)
        ret = "%s {" % self.fmt.name
        col_count = 0
        for c in self.fmt.columns:
            val = self.__getattr__(c)
            if is_quiet_nan(val):
                val = "qnan"
            # Add the value to the return string
            if is_py3:
                ret += "%s : %s, " % (c, val)
            else:
                try:
                    ret += "%s : %s, " % (c, val)
                except UnicodeDecodeError:
                    ret += "%s : %s, " % (c, to_string(val))
            col_count += 1
        if col_count != 0:
            ret = ret[:-2]
        return ret + '}'

    def dump_verbose_bitmask(self, f, c, val, field_metadata):
        try:
            try:
                bitmask = field_metadata["bitmask"]
            except Exception:
                return

            # work out how many bits to show:
            t = field_metadata.get("type")
            bit_count = None
            if t == "uint8_t":
                bit_count = 8
            elif t == "uint16_t":
                bit_count = 16
            elif t == "uint32_t":
                bit_count = 32

            if bit_count is None:
                return

            highest = -1

            # we show bit values at least up to the highest bit set:
            for i in range(bit_count):
                if val & (1<<i):
                    highest = i

            # we show bit values at least up until the highest
            # bit we have a description for:
            for bit in bitmask.bit:
                bit_offset = int(math.log(bit["value"], 2))
                if bit_offset > highest:
                    highest = bit_offset

            for i in range(bit_offset):
                bit_value = 1 << i
                done = False
                for bit in bitmask.bit:
                    if bit["value"] != bit_value:
                        continue
                    if val & bit_value:
                        bang = ""
                    else:
                        bang = "!"
                    bit_name = bit.get('name')
                    bit_desc = None
                    try:
                        bit_desc = bit["description"]
                    except KeyError:
                        pass
                    if bit_desc is None:
                        f.write("        %s%s\n" % (bang, bit_name,))
                    else:
                        f.write("        %s%s (%s)\n" % (bang, bit_name, bit_desc))
                    done = True
                    break
                if not done:
                    f.write("        %{s}UNKNOWN_BIT%s\n" % (bang, str(i)))
        except Exception as e:
            # print(e)
            pass

    def dump_verbose(self, f):
        is_py3 = sys.version_info >= (3,0)
        timestamp = "%s.%03u" % (
            time.strftime("%Y-%m-%d %H:%M:%S", time.localtime(self._timestamp)),
            int(self._timestamp*1000.0)%1000)
        f.write("%s: %s\n" % (timestamp, self.fmt.name))

        field_metadata_by_name = {}
        try:
            metadata_tree = self._parent.metadata.metadata_tree()
            metadata = metadata_tree[self.fmt.name]
            for fm in metadata["fields"].field:
                field_metadata_by_name[fm.get("name")] = fm
        except Exception as e:
            # print(e)
            pass

        for c in self.fmt.columns:
            # Get the value
            val = self.__getattr__(c)
            # Handle quiet nan
            if is_quiet_nan(val):
                val = "qnan"
            # Output the field label and value
            if is_py3:
                f.write("    %s: %s" % (c, val))
            else:
                try:
                    f.write("    %s: %s" % (c, val))
                except UnicodeDecodeError:
                    f.write("    %s: %s" % (c, to_string(val)))
            # Append the unit to the output
            unit = self.fmt.get_unit(c)
            if unit == "":
                # No unit specified - just output the newline
                f.write("\n")
            elif unit.startswith("rad"):
                # For rad or rad/s, add the degrees conversion too
                f.write(" %s (%s %s)\n" % (unit, math.degrees(val), unit.replace("rad","deg")))
            else:
                # Append the unit
                f.write(" %s\n" % (unit))

            # if this is a bitmask then print out all bits set:
            if c in field_metadata_by_name:
                self.dump_verbose_bitmask(f, c, val, field_metadata_by_name[c])

    def get_msgbuf(self):
        '''create a binary message buffer for a message'''
        values = []
        is_py2 = sys.version_info < (3,0)
        for i in range(len(self.fmt.columns)):
            if i >= len(self.fmt.msg_mults):
                continue
            mul = self.fmt.msg_mults[i]
            name = self.fmt.columns[i]
            if name == 'Mode' and 'ModeNum' in self.fmt.columns:
                name = 'ModeNum'
            v = self.__getattr__(name)
            if is_py2:
                if isinstance(v,unicode): # NOQA
                    v = str(v)
                elif isinstance(v, array.array):
                    v = v.tostring()
            else:
                if isinstance(v,str):
                    try:
                        v = bytes(v,'ascii')
                    except UnicodeEncodeError:
                        v = v.encode()
                elif isinstance(v, array.array):
                    v = v.tobytes()
            if mul is not None:
                v /= mul
                v = int(round(v))
            values.append(v)

        ret1 = struct.pack("BBB", 0xA3, 0x95, self.fmt.type)
        try:
            ret2 = struct.pack(self.fmt.msg_struct, *values)
        except Exception as ex:
            return None
        return ret1 + ret2

    def get_fieldnames(self):
        return self._fieldnames

    def __getitem__(self, key):
        '''support indexing, allowing for multi-instance sensors in one message'''
        if self.fmt.instance_field is None:
            raise IndexError()
        k = '%s[%s]' % (self.fmt.name, str(key))
        if not k in self._parent.messages:
            raise IndexError()
        return self._parent.messages[k]


class DFReaderClock(object):
    '''base class for all the different ways we count time in logs'''

    def __init__(self):
        self.set_timebase(0)
        self.timestamp = 0

    def _gpsTimeToTime(self, week, msec):
        '''convert GPS week and TOW to a time in seconds since 1970'''
        epoch = 86400*(10*365 + int((1980-1969)/4) + 1 + 6 - 2)
        return epoch + 86400*7*week + msec*0.001 - 18

    def set_timebase(self, base):
        self.timebase = base

    def message_arrived(self, m):
        pass

    def rewind_event(self):
        pass


class DFReaderClock_usec(DFReaderClock):
    '''DFReaderClock_usec - use microsecond timestamps from messages'''
    def __init__(self):
        DFReaderClock.__init__(self)

    def find_time_base(self, gps, first_us_stamp):
        '''work out time basis for the log - even newer style'''
        t = self._gpsTimeToTime(gps.GWk, gps.GMS)
        self.set_timebase(t - gps.TimeUS*0.000001)
        # this ensures FMT messages get appropriate timestamp:
        self.timestamp = self.timebase + first_us_stamp*0.000001

    def type_has_good_TimeMS(self, type):
        '''The TimeMS in some messages is not from *our* clock!'''
        if type.startswith('ACC'):
            return False
        if type.startswith('GYR'):
            return False
        return True

    def should_use_msec_field0(self, m):
        if not self.type_has_good_TimeMS(m.get_type()):
            return False
        if 'TimeMS' != m._fieldnames[0]:
            return False
        if self.timebase + m.TimeMS*0.001 < self.timestamp:
            return False
        return True

    def set_message_timestamp(self, m):
        if 'TimeUS' == m._fieldnames[0]:
            # only format messages don't have a TimeUS in them...
            m._timestamp = self.timebase + m.TimeUS*0.000001
        elif self.should_use_msec_field0(m):
            # ... in theory. I expect there to be some logs which are not
            # "pure":
            m._timestamp = self.timebase + m.TimeMS*0.001
        else:
            m._timestamp = self.timestamp
        self.timestamp = m._timestamp


class DFReaderClock_msec(DFReaderClock):
    '''DFReaderClock_msec - a format where many messages have TimeMS in
    their formats, and GPS messages have a "T" field giving msecs'''
    def find_time_base(self, gps, first_ms_stamp):
        '''work out time basis for the log - new style'''
        t = self._gpsTimeToTime(gps.Week, gps.TimeMS)
        self.set_timebase(t - gps.T*0.001)
        self.timestamp = self.timebase + first_ms_stamp*0.001

    def set_message_timestamp(self, m):
        if 'TimeMS' == m._fieldnames[0]:
            m._timestamp = self.timebase + m.TimeMS*0.001
        elif m.get_type() in ['GPS', 'GPS2']:
            m._timestamp = self.timebase + m.T*0.001
        else:
            m._timestamp = self.timestamp
        self.timestamp = m._timestamp


class DFReaderClock_px4(DFReaderClock):
    '''DFReaderClock_px4 - a format where a starting time is explicitly
    given in a message'''
    def __init__(self):
        DFReaderClock.__init__(self)
        self.px4_timebase = 0

    def find_time_base(self, gps):
        '''work out time basis for the log - PX4 native'''
        t = gps.GPSTime * 1.0e-6
        self.timebase = t - self.px4_timebase

    def set_px4_timebase(self, time_msg):
        self.px4_timebase = time_msg.StartTime * 1.0e-6

    def set_message_timestamp(self, m):
        m._timestamp = self.timebase + self.px4_timebase

    def message_arrived(self, m):
        type = m.get_type()
        if type == 'TIME' and 'StartTime' in m._fieldnames:
            self.set_px4_timebase(m)


class DFReaderClock_gps_interpolated(DFReaderClock):
    '''DFReaderClock_gps_interpolated - for when the only real references
    in a message are GPS timestamps'''
    def __init__(self):
        DFReaderClock.__init__(self)
        self.msg_rate = {}
        self.counts = {}
        self.counts_since_gps = {}

    def rewind_event(self):
        '''reset counters on rewind'''
        self.counts = {}
        self.counts_since_gps = {}

    def message_arrived(self, m):
        type = m.get_type()
        if type not in self.counts:
            self.counts[type] = 1
        else:
            self.counts[type] += 1
        # this preserves existing behaviour - but should we be doing this
        # if type == 'GPS'?
        if type not in self.counts_since_gps:
            self.counts_since_gps[type] = 1
        else:
            self.counts_since_gps[type] += 1

        if type == 'GPS' or type == 'GPS2':
            self.gps_message_arrived(m)

    def gps_message_arrived(self, m):
        '''adjust time base from GPS message'''
        # msec-style GPS message?
        gps_week = getattr(m, 'Week', None)
        gps_timems = getattr(m, 'TimeMS', None)
        if gps_week is None:
            # usec-style GPS message?
            gps_week = getattr(m, 'GWk', None)
            gps_timems = getattr(m, 'GMS', None)
            if gps_week is None:
                if getattr(m, 'GPSTime', None) is not None:
                    # PX4-style timestamp; we've only been called
                    # because we were speculatively created in case no
                    # better clock was found.
                    return

        if gps_week is None and hasattr(m,'Wk'):
            # AvA-style logs
            gps_week = getattr(m, 'Wk')
            gps_timems = getattr(m, 'TWk')
            if gps_week is None or gps_timems is None:
                return

        t = self._gpsTimeToTime(gps_week, gps_timems)

        deltat = t - self.timebase
        if deltat <= 0:
            return

        for type in self.counts_since_gps:
            rate = self.counts_since_gps[type] / deltat
            if rate > self.msg_rate.get(type, 0):
                self.msg_rate[type] = rate
        self.msg_rate['IMU'] = 50.0
        self.timebase = t
        self.counts_since_gps = {}

    def set_message_timestamp(self, m):
        rate = self.msg_rate.get(m.fmt.name, 50.0)
        if int(rate) == 0:
            rate = 50
        count = self.counts_since_gps.get(m.fmt.name, 0)
        m._timestamp = self.timebase + count/rate


class DFMetaData(object):
    '''handle dataflash messages metadata'''
    def __init__(self, parent):
        self.parent = parent
        self.data = None
        self.metadata_load_attempted = False

    def reset(self):
        '''clear cached data'''
        self.data = None
        self.metadata_load_attempted = False

    @staticmethod
    def dot_pymavlink(*args):
        '''return a path to store pymavlink data'''
        if 'HOME' not in os.environ:
            dir = os.path.join(os.environ['LOCALAPPDATA'], '.pymavlink')
        else:
            dir = os.path.join(os.environ['HOME'], '.pymavlink')
        if len(args) == 0:
            return dir
        return os.path.join(dir, *args)

    @staticmethod
    def download_url(url):
        '''download a URL and return the content'''
        if sys.version_info.major < 3:
            from urllib2 import urlopen as url_open
            from urllib2 import URLError as url_error
        else:
            from urllib.request import urlopen as url_open
            from urllib.error import URLError as url_error
        try:
            resp = url_open(url)
        except url_error as e:
            print('Error downloading %s : %s' % (url, e))
            return None
        return resp.read()

    @staticmethod
    def download():
        # Make sure the folder to store XML in has been created
        os.makedirs(DFMetaData.dot_pymavlink('LogMessages'), exist_ok=True)
        # Loop through vehicles to download
        for vehicle in ['Rover', 'Copter', 'Plane', 'Tracker', 'Blimp', 'Sub']:
            url = 'http://autotest.ardupilot.org/LogMessages/%s/LogMessages.xml.gz' % vehicle
            file = DFMetaData.dot_pymavlink('LogMessages', "%s.xml" % vehicle)
            print("Downloading %s as %s" % (url, file))
            data = DFMetaData.download_url(url)
            if data is None:
                continue
            # decompress it...
            with gzip.GzipFile(fileobj=io.BytesIO(data)) as gz:
                data = gz.read()
            try:
                open(file, mode='wb').write(data)
            except Exception as e:
                print("Failed to save to %s : %s" % (file, e))

    def metadata_tree(self, verbose=False):
        ''' return a map between a log message and its metadata. May return
        None if data is not available '''
        # If we've already tried loading data, use it if we have it
        # This avoid repeated attempts, when the file is not there
        if self.metadata_load_attempted:
            return self.data
        self.metadata_load_attempted = True
        # Get file name, based on vehicle type
        mapping = {mavutil.mavlink.MAV_TYPE_GROUND_ROVER : "Rover",
                   mavutil.mavlink.MAV_TYPE_FIXED_WING : "Plane",
                   mavutil.mavlink.MAV_TYPE_QUADROTOR : "Copter",
                   mavutil.mavlink.MAV_TYPE_HELICOPTER : "Copter",
                   mavutil.mavlink.MAV_TYPE_ANTENNA_TRACKER : "Tracker",
                   mavutil.mavlink.MAV_TYPE_SUBMARINE : "Sub",
                   mavutil.mavlink.MAV_TYPE_AIRSHIP : "Blimp",
                   }
        if self.parent.mav_type not in mapping:
            return None
        path = DFMetaData.dot_pymavlink("LogMessages", "%s.xml" % mapping[self.parent.mav_type])
        # Does the file exist?
        if not os.path.exists(path):
            if verbose:
                print("Can't find '%s'" % path)
                print("Please run 'logmessage download' from MAVExplorer, or call")
                print("DFMetaData.download() from Python.")
            return None
        # Read in the XML
        xml = open(path, 'rb').read()
        from lxml import objectify
        objectify.enable_recursive_str()
        tree = objectify.fromstring(xml)
        data = {}
        for p in tree.logformat:
            n = p.get('name')
            data[n] = p
        # Cache and return data
        self.data = data
        return self.data

    def print_help(self, msg):
        '''print help for a log message'''
        data = self.metadata_tree(verbose=True)
        if data is None:
            return
        if msg not in data:
            print("No help found for message: %s" % msg)
            return
        node = data[msg]
        # Message name and description
        print("Log Message: %s\n%s\n" % (msg, node.description.text))
        # Protect against replay messages which dont list their fields
        if not hasattr(node.fields, 'field'):
            return
        namelist = []
        unitlist = []
        # Loop through fields to build list of name/units
        for f in node.fields.field:
            namelist.append(f.get('name'))
            units = f.get('units')
            dtype = f.get('type')
            if units:
                unitlist.append("[%s] " % units)
            elif 'char' in dtype:
                unitlist.append("[%s] " % dtype)
            elif hasattr(f, 'enum'):
                unitlist.append("[enum] ")
            elif hasattr(f, 'bitmask'):
                unitlist.append("[bitmask] ")
            else:
                unitlist.append("")
        # Now get the max string length from each list
        namelen = len(max(namelist, key=len))
        unitlen = len(max(unitlist, key=len))
        # Loop through fields again to do the actual printing
        for i in range(0, len(namelist)):
            desc = node.fields.field[i].description.text
            print("%-*s %-*s: %s" % (namelen, namelist[i], unitlen, unitlist[i], desc))

    def get_description(self, msg):
        '''get the description of a log message'''
        data = self.metadata_tree()
        if data is None:
            return None
        if msg in data:
            return data[msg].description.text
        return ""


class DFReader(object):
    '''parse a generic dataflash file'''
    def __init__(self):
        # read the whole file into memory for simplicity
        self.clock = None
        self.timestamp = 0
        self.mav_type = mavutil.mavlink.MAV_TYPE_FIXED_WING
        self.verbose = False
        self.params = {}
        self._flightmodes = None
        self.messages = {
            'MAV': self,
            '__MAV__': self,  # avoids conflicts with messages actually called "MAV"
        }
        self.percent = 0
        self.unit_lookup = {}  # lookup table of units defined by UNIT messages
        self.mult_lookup = {}  # lookup table of multipliers defined by MULT messages
        self.metadata = DFMetaData(self)

    def _rewind(self):
        '''reset state on rewind'''
        # be careful not to replace self.messages with a new hash;
        # some people have taken a reference to self.messages and we
        # need their messages to disappear to.  If they want their own
        # copy they can copy.copy it!
        self.messages.clear()
        self.messages = {
            'MAV': self,
            '__MAV__': self,  # avoids conflicts with messages actually called "MAV"
        }
        if self._flightmodes is not None and len(self._flightmodes) > 0:
            self.flightmode = self._flightmodes[0][0]
        else:
            self.flightmode = "UNKNOWN"
        self.percent = 0
        if self.clock:
            self.clock.rewind_event()

    def init_clock_px4(self, px4_msg_time, px4_msg_gps):
        self.clock = DFReaderClock_px4()
        if not self._zero_time_base:
            self.clock.set_px4_timebase(px4_msg_time)
            self.clock.find_time_base(px4_msg_gps)
        return True

    def init_clock_msec(self):
        # it is a new style flash log with full timestamps
        self.clock = DFReaderClock_msec()

    def init_clock_usec(self):
        self.clock = DFReaderClock_usec()

    def init_clock_gps_interpolated(self, clock):
        self.clock = clock

    def init_clock(self):
        '''work out time basis for the log'''

        self._rewind()

        # speculatively create a gps clock in case we don't find anything
        # better
        gps_clock = DFReaderClock_gps_interpolated()
        self.clock = gps_clock

        px4_msg_time = None
        px4_msg_gps = None
        gps_interp_msg_gps1 = None
        first_us_stamp = None
        first_ms_stamp = None

        have_good_clock = False
        while True:
            m = self.recv_msg()
            if m is None:
                break

            type = m.get_type()

            if first_us_stamp is None:
                first_us_stamp = getattr(m, "TimeUS", None)

            if first_ms_stamp is None and (type != 'GPS' and type != 'GPS2'):
                # Older GPS messages use TimeMS for msecs past start
                # of gps week
                first_ms_stamp = getattr(m, "TimeMS", None)

            if type == 'GPS' or type == 'GPS2':
                if getattr(m, "TimeUS", 0) != 0 and \
                   getattr(m, "GWk", 0) != 0:  # everything-usec-timestamped
                    self.init_clock_usec()
                    if not self._zero_time_base:
                        self.clock.find_time_base(m, first_us_stamp)
                    have_good_clock = True
                    break
                if getattr(m, "T", 0) != 0 and \
                   getattr(m, "Week", 0) != 0:  # GPS is msec-timestamped
                    if first_ms_stamp is None:
                        first_ms_stamp = m.T
                    self.init_clock_msec()
                    if not self._zero_time_base:
                        self.clock.find_time_base(m, first_ms_stamp)
                    have_good_clock = True
                    break
                if getattr(m, "GPSTime", 0) != 0:  # px4-style-only
                    px4_msg_gps = m
                if getattr(m, "Week", 0) != 0:
                    if (gps_interp_msg_gps1 is not None and
                        (gps_interp_msg_gps1.TimeMS != m.TimeMS or
                         gps_interp_msg_gps1.Week != m.Week)):
                        # we've received two distinct, non-zero GPS
                        # packets without finding a decent clock to
                        # use; fall back to interpolation. Q: should
                        # we wait a few more messages befoe doing
                        # this?
                        self.init_clock_gps_interpolated(gps_clock)
                        have_good_clock = True
                        break
                    gps_interp_msg_gps1 = m

            elif type == 'TIME':
                '''only px4-style logs use TIME'''
                if getattr(m, "StartTime", None) is not None:
                    px4_msg_time = m

            if px4_msg_time is not None and px4_msg_gps is not None:
                self.init_clock_px4(px4_msg_time, px4_msg_gps)
                have_good_clock = True
                break

#        print("clock is " + str(self.clock))
        if not have_good_clock:
            # we failed to find any GPS messages to set a time
            # base for usec and msec clocks.  Also, not a
            # PX4-style log
            if first_us_stamp is not None:
                self.init_clock_usec()
            elif first_ms_stamp is not None:
                self.init_clock_msec()

        self._rewind()

        return

    def _set_time(self, m):
        '''set time for a message'''
        # really just left here for profiling
        m._timestamp = self.timestamp
        if len(m._fieldnames) > 0 and self.clock is not None:
            self.clock.set_message_timestamp(m)

    def recv_msg(self):
        return self._parse_next()

    def _add_msg(self, m):
        '''add a new message'''
        type = m.get_type()
        self.messages[type] = m
        if m.fmt.instance_field is not None:
            i = m.__getattr__(m.fmt.instance_field)
            self.messages["%s[%s]" % (type, str(i))] = m

        if self.clock:
            self.clock.message_arrived(m)

        if type == 'MSG' and hasattr(m,'Message'):
            if m.Message.find("Rover") != -1:
                self.mav_type = mavutil.mavlink.MAV_TYPE_GROUND_ROVER
            elif m.Message.find("Plane") != -1:
                self.mav_type = mavutil.mavlink.MAV_TYPE_FIXED_WING
            elif m.Message.find("Copter") != -1:
                self.mav_type = mavutil.mavlink.MAV_TYPE_QUADROTOR
            elif m.Message.startswith("Antenna"):
                self.mav_type = mavutil.mavlink.MAV_TYPE_ANTENNA_TRACKER
            elif m.Message.find("ArduSub") != -1:
                self.mav_type = mavutil.mavlink.MAV_TYPE_SUBMARINE
            elif m.Message.find("Blimp") != -1:
                self.mav_type = mavutil.mavlink.MAV_TYPE_AIRSHIP
        if type == 'VER' and hasattr(m,'BU'):
            build_types = { 1: mavutil.mavlink.MAV_TYPE_GROUND_ROVER,
                            2: mavutil.mavlink.MAV_TYPE_QUADROTOR,
                            3: mavutil.mavlink.MAV_TYPE_FIXED_WING,
                            4: mavutil.mavlink.MAV_TYPE_ANTENNA_TRACKER,
                            7: mavutil.mavlink.MAV_TYPE_SUBMARINE,
                            13: mavutil.mavlink.MAV_TYPE_HELICOPTER,
                            12: mavutil.mavlink.MAV_TYPE_AIRSHIP,
                            }
            mavtype = build_types.get(m.BU,None)
            if mavtype is not None:
                self.mav_type = mavtype
        if type == 'MODE':
            if hasattr(m,'Mode') and isinstance(m.Mode, str):
                self.flightmode = m.Mode.upper()
            elif 'ModeNum' in m._fieldnames:
                mapping = mavutil.mode_mapping_bynumber(self.mav_type)
                if mapping is not None and m.ModeNum in mapping:
                    self.flightmode = mapping[m.ModeNum]
                else:
                    self.flightmode = 'UNKNOWN'
            elif hasattr(m,'Mode'):
                self.flightmode = mavutil.mode_string_acm(m.Mode)
        if type == 'STAT' and 'MainState' in m._fieldnames:
            self.flightmode = mavutil.mode_string_px4(m.MainState)
        if type == 'PARM' and getattr(m, 'Name', None) is not None:
            self.params[m.Name] = m.Value
            if hasattr(m,'Default') and not math.isnan(m.Default):
                if not hasattr(self,'param_defaults'):
                    self.param_defaults = {}
                self.param_defaults[m.Name] = m.Default
        self._set_time(m)

    def recv_match(self, condition=None, type=None, blocking=False):
        '''recv the next message that matches the given condition
        type can be a string or a list of strings'''
        if type is not None:
            if isinstance(type, str):
                type = set([type])
            elif isinstance(type, list):
                type = set(type)
        while True:
            if type is not None:
                self.skip_to_type(type)
            m = self.recv_msg()
            if m is None:
                return None
            if type is not None and not m.get_type() in type:
                continue
            if not mavutil.evaluate_condition(condition, self.messages):
                continue
            return m

    def check_condition(self, condition):
        '''check if a condition is true'''
        return mavutil.evaluate_condition(condition, self.messages)

    def param(self, name, default=None):
        '''convenient function for returning an arbitrary MAVLink
           parameter with a default'''
        if name not in self.params:
            return default
        return self.params[name]

    def flightmode_list(self):
        '''return an array of tuples for all flightmodes in log. Tuple is (modestring, t0, t1)'''
        tstamp = None
        fmode = None
        if self._flightmodes is None:
            self._rewind()
            self._flightmodes = []
            types = set(['MODE'])
            while True:
                m = self.recv_match(type=types)
                if m is None:
                    break
                tstamp = m._timestamp
                if self.flightmode == fmode:
                    continue
                if len(self._flightmodes) > 0:
                    (mode, t0, t1) = self._flightmodes[-1]
                    self._flightmodes[-1] = (mode, t0, tstamp)
                self._flightmodes.append((self.flightmode, tstamp, None))
                fmode = self.flightmode
            if tstamp is not None:
                (mode, t0, t1) = self._flightmodes[-1]
                self._flightmodes[-1] = (mode, t0, self.last_timestamp())

        self._rewind()
        return self._flightmodes
    
    def close(self):
        '''close the log file'''
        self.data_map.close()
        self.filehandle.close()
    

class DFReader_binary(DFReader):
    '''parse a binary dataflash file'''
    def __init__(self, filename, zero_time_base=False, progress_callback=None):
        DFReader.__init__(self)
        # read the whole file into memory for simplicity
        self.filehandle = open(filename, 'r')
        self.filehandle.seek(0, 2)
        self.data_len = self.filehandle.tell()
        self.filehandle.seek(0)
        if platform.system() == "Windows":
            self.data_map = mmap.mmap(self.filehandle.fileno(), self.data_len, None, mmap.ACCESS_READ)
        else:
            self.data_map = mmap.mmap(self.filehandle.fileno(), self.data_len, mmap.MAP_PRIVATE, mmap.PROT_READ)

        self.HEAD1 = 0xA3
        self.HEAD2 = 0x95
        self.unpackers = {}
        if sys.version_info.major < 3:
            self.HEAD1 = chr(self.HEAD1)
            self.HEAD2 = chr(self.HEAD2)
        self.formats = {
            0x80: DFFormat(0x80,
                           'FMT',
                           89,
                           'BBnNZ',
                           "Type,Length,Name,Format,Columns")
        }
        self._zero_time_base = zero_time_base
        self.prev_type = None
        self.init_clock()
        self.prev_type = None
        self._rewind()
        self.init_arrays(progress_callback)

    def _rewind(self):
        '''rewind to start of log'''
        DFReader._rewind(self)
        self.offset = 0
        self.remaining = self.data_len
        self.type_nums = None
        self.timestamp = 0

    def rewind(self):
        '''rewind to start of log'''
        self._rewind()

    def init_arrays(self, progress_callback=None):
        '''initialise arrays for fast recv_match()'''
        self.offsets = []
        self.counts = []
        self._count = 0
        self.name_to_id = {}
        self.id_to_name = {}
        type_instances = {}
        for i in range(256):
            self.offsets.append([])
            self.counts.append(0)
        fmt_type = 0x80
        fmtu_type = None
        unit_type = None
        mult_type = None
        ofs = 0
        pct = 0
        HEAD1 = self.HEAD1
        HEAD2 = self.HEAD2
        lengths = [-1] * 256

        while ofs+3 < self.data_len:
            hdr = self.data_map[ofs:ofs+3]
            if hdr[0] != HEAD1 or hdr[1] != HEAD2:
                # avoid end of file garbage, 528 bytes has been use consistently throughout this implementation
                # but it needs to be at least 249 bytes which is the block based logging page size (256) less a 6 byte header and
                # one byte of data. Block based logs are sized in pages which means they can have up to 249 bytes of trailing space.
                if self.data_len - ofs >= 528 or self.data_len < 528:
                    print("bad header 0x%02x 0x%02x at %d" % (u_ord(hdr[0]), u_ord(hdr[1]), ofs), file=sys.stderr)
                ofs += 1
                continue
            mtype = u_ord(hdr[2])
            self.offsets[mtype].append(ofs)

            if lengths[mtype] == -1:
                if not mtype in self.formats:
                    if self.data_len - ofs >= 528 or self.data_len < 528:
                        print("unknown msg type 0x%02x (%u) at %d" % (mtype, mtype, ofs),
                              file=sys.stderr)
                    break
                self.offset = ofs
                self._parse_next()
                fmt = self.formats[mtype]
                lengths[mtype] = fmt.len
            elif self.formats[mtype].instance_field is not None:
                fmt = self.formats[mtype]
                # see if we've has this instance value before
                idata = self.data_map[ofs+3+fmt.instance_ofs:ofs+3+fmt.instance_ofs+fmt.instance_len]
                if not mtype in type_instances:
                    type_instances[mtype] = set()
                if not idata in type_instances[mtype]:
                    # its a new one, need to parse it so we have the complete set of instances
                    type_instances[mtype].add(idata)
                    self.offset = ofs
                    self._parse_next()

            self.counts[mtype] += 1
            mlen = lengths[mtype]

            if mtype == fmt_type:
                body = self.data_map[ofs+3:ofs+mlen]
                if len(body)+3 < mlen:
                    break
                fmt = self.formats[mtype]
                elements = list(struct.unpack(fmt.msg_struct, body))
                ftype = elements[0]
                mfmt = DFFormat(
                    ftype,
                    null_term(elements[2]), elements[1],
                    null_term(elements[3]), null_term(elements[4]),
                    oldfmt=self.formats.get(ftype,None))
                self.formats[ftype] = mfmt
                self.name_to_id[mfmt.name] = mfmt.type
                self.id_to_name[mfmt.type] = mfmt.name
                if mfmt.name == 'FMTU':
                    fmtu_type = mfmt.type
                if mfmt.name == 'UNIT':
                    unit_type = mfmt.type
                if mfmt.name == 'MULT':
                    mult_type = mfmt.type

            # Handle FMTU messages by updating the DFFormat class with the
            # unit/multiplier information
            if fmtu_type is not None and mtype == fmtu_type:
                fmt = self.formats[mtype]
                body = self.data_map[ofs+3:ofs+mlen]
                if len(body)+3 < mlen:
                    break
                elements = list(struct.unpack(fmt.msg_struct, body))
                ftype = int(elements[1])
                if ftype in self.formats:
                    fmt2 = self.formats[ftype]
                    if 'UnitIds' in fmt.colhash:
                        fmt2.set_unit_ids(null_term(elements[fmt.colhash['UnitIds']]), self.unit_lookup)
                    if 'MultIds' in fmt.colhash:
                        fmt2.set_mult_ids(null_term(elements[fmt.colhash['MultIds']]), self.mult_lookup)

            # Handle UNIT messages by updating the unit_lookup dictionary
            if unit_type is not None and mtype == unit_type:
                fmt = self.formats[mtype]
                body = self.data_map[ofs+3:ofs+mlen]
                if len(body)+3 < mlen:
                    break
                elements = list(struct.unpack(fmt.msg_struct, body))
                self.unit_lookup[chr(elements[1])] = null_term(elements[2])

            # Handle MULT messages by updating the mult_lookup dictionary
            if mult_type is not None and mtype == mult_type:
                fmt = self.formats[mtype]
                body = self.data_map[ofs+3:ofs+mlen]
                if len(body)+3 < mlen:
                    break
                elements = list(struct.unpack(fmt.msg_struct, body))
                # Even though the multiplier value is logged as a double, the
                # values in log files look to be single-precision values that have
                # been cast to a double.
                # To ensure that the values saved here can be used to index the
                # MULT_TO_PREFIX table, we round them to 7 significant decimal digits
                mult = float("%.7g" % (elements[2]))
                self.mult_lookup[chr(elements[1])] = mult

            ofs += mlen
            if progress_callback is not None:
                new_pct = (100 * ofs) // self.data_len
                if new_pct != pct:
                    progress_callback(new_pct)
                    pct = new_pct

        for i in range(256):
            self._count += self.counts[i]
        self.offset = 0

    def last_timestamp(self):
        '''get the last timestamp in the log'''
        highest_offset = 0
        second_highest_offset = 0
        for i in range(256):
            if self.counts[i] == -1:
                continue
            if len(self.offsets[i]) == 0:
                continue
            ofs = self.offsets[i][-1]
            if ofs > highest_offset:
                second_highest_offset = highest_offset
                highest_offset = ofs
            elif ofs > second_highest_offset:
                second_highest_offset = ofs
        self.offset = highest_offset
        m = self.recv_msg()
        if m is None:
            self.offset = second_highest_offset
            m = self.recv_msg()
        return m._timestamp


    def skip_to_type(self, type):
        '''skip fwd to next msg matching given type set'''

        if self.type_nums is None:
            # always add some key msg types so we can track flightmode, params etc
            type = type.copy()
            type.update(set(['MODE','MSG','PARM','STAT','ORGN','VER']))
            self.indexes = []
            self.type_nums = []
            for t in type:
                if not t in self.name_to_id:
                    continue
                self.type_nums.append(self.name_to_id[t])
                self.indexes.append(0)
        smallest_index = -1
        smallest_offset = self.data_len
        for i in range(len(self.type_nums)):
            mtype = self.type_nums[i]
            if self.indexes[i] >= self.counts[mtype]:
                continue
            ofs = self.offsets[mtype][self.indexes[i]]
            if ofs < smallest_offset:
                smallest_offset = ofs
                smallest_index = i
        if smallest_index >= 0:
            self.indexes[smallest_index] += 1
            self.offset = smallest_offset

    def _parse_next(self):
        '''read one message, returning it as an object'''

        # skip over bad messages; after this loop has run msg_type
        # indicates the message which starts at self.offset (including
        # signature bytes and msg_type itself)
        skip_type = None
        skip_start = 0
        while True:
            if self.data_len - self.offset < 3:
                return None

            hdr = self.data_map[self.offset:self.offset+3]
            if hdr[0] == self.HEAD1 and hdr[1] == self.HEAD2:
                # signature found
                if skip_type is not None:
                    # emit message about skipped bytes
                    if self.remaining >= 528:
                        # APM logs often contain garbage at end
                        skip_bytes = self.offset - skip_start
                        print("Skipped %u bad bytes in log at offset %u, type=%s (prev=%s)" %
                              (skip_bytes, skip_start, skip_type, self.prev_type),
                          file=sys.stderr)
                    skip_type = None
                # check we recognise this message type:
                msg_type = u_ord(hdr[2])
                if msg_type in self.formats:
                    # recognised message found
                    self.prev_type = msg_type
                    break;
                # message was not recognised; fall through so these
                # bytes are considered "skipped".  The signature bytes
                # are easily recognisable in the "Skipped bytes"
                # message.
            if skip_type is None:
                skip_type = (u_ord(hdr[0]), u_ord(hdr[1]), u_ord(hdr[2]))
                skip_start = self.offset
            self.offset += 1
            self.remaining -= 1

        self.offset += 3
        self.remaining = self.data_len - self.offset

        fmt = self.formats[msg_type]
        if self.remaining < fmt.len-3:
            # out of data - can often happen half way through a message
            if self.verbose:
                print("out of data", file=sys.stderr)
            return None
        body = self.data_map[self.offset:self.offset+fmt.len-3]
        elements = None
        try:
            if not msg_type in self.unpackers:
                self.unpackers[msg_type] = struct.Struct(fmt.msg_struct).unpack
            elements = list(self.unpackers[msg_type](body))
        except Exception as ex:
            print(ex)
            if self.remaining < 528:
                # we can have garbage at the end of an APM2 log
                return None
            # we should also cope with other corruption; logs
            # transferred via DataFlash_MAVLink may have blocks of 0s
            # in them, for example
            print("Failed to parse %s/%s with len %u (remaining %u)" %
                  (fmt.name, fmt.msg_struct, len(body), self.remaining),
                  file=sys.stderr)
        if elements is None:
            return self._parse_next()
        name = fmt.name
        # transform elements which can't be done at unpack time:
        for a_index in fmt.a_indexes:
            try:
                elements[a_index] = array.array('h', elements[a_index])
            except Exception as e:
                print("Failed to transform array: %s" % str(e),
                      file=sys.stderr)

        if name == 'FMT':
            # add to formats
            # name, len, format, headings
            try:
                ftype = elements[0]
                mfmt = DFFormat(
                    ftype,
                    null_term(elements[2]), elements[1],
                    null_term(elements[3]), null_term(elements[4]),
                    oldfmt=self.formats.get(ftype,None))
                self.formats[ftype] = mfmt
            except Exception:
                return self._parse_next()

        self.offset += fmt.len - 3
        self.remaining = self.data_len - self.offset
        m = DFMessage(fmt, elements, True, self)

        if m.fmt.name == 'FMTU':
            # add to units information
            FmtType = int(elements[0])
            UnitIds = elements[1]
            MultIds = elements[2]
            if FmtType in self.formats:
                fmt = self.formats[FmtType]
                fmt.set_unit_ids(UnitIds, self.unit_lookup)
                fmt.set_mult_ids(MultIds, self.mult_lookup)

        try:
            self._add_msg(m)
        except Exception as ex:
            print("bad msg at offset %u" % self.offset, ex)
            pass
        self.percent = 100.0 * (self.offset / float(self.data_len))

        return m

    def find_unused_format(self):
        '''find an unused format code'''
        for i in range(254, 1, -1):
            if not i in self.formats:
                return i
        return None

    def add_format(self, fmt):
        '''add a new format'''
        new_type = self.find_unused_format()
        if new_type is None:
            return None
        fmt.type = new_type
        self.formats[new_type] = fmt
        return fmt

    def make_msgbuf(self, fmt, values):
        '''make a message buffer from a list of values'''
        ret = struct.pack("BBB", 0xA3, 0x95, fmt.type)
        ret += struct.pack(fmt.msg_struct, *values)
        return ret

    def make_format_msgbuf(self, fmt):
        '''make a message buffer for a FMT message'''
        fmt_fmt = self.formats[0x80]
        ret = struct.pack("BBB", 0xA3, 0x95, 0x80)
        ret += struct.pack(fmt_fmt.msg_struct, *[fmt.type,struct.calcsize(fmt.msg_struct)+3,
                                                 fmt.name.encode('ascii'),
                                                 fmt.format.encode('ascii'),
                                                 ','.join(fmt.columns).encode('ascii')])
        return ret
    

def DFReader_is_text_log(filename):
    '''return True if a file appears to be a valid text log'''
    with open(filename, 'r') as f:
        ret = (f.read(8000).find('FMT,') != -1)

    return ret


class DFReader_text(DFReader):
    '''parse a text dataflash file'''
    def __init__(self, filename, zero_time_base=False, progress_callback=None):
        DFReader.__init__(self)
        self.name_to_id = {}
        # read the whole file into memory for simplicity
        self.filehandle = open(filename, 'r')
        self.filehandle.seek(0, 2)
        self.data_len = self.filehandle.tell()
        self.filehandle.seek(0, 0)
        if platform.system() == "Windows":
            self.data_map = mmap.mmap(self.filehandle.fileno(), self.data_len, None, mmap.ACCESS_READ)
        else:
            self.data_map = mmap.mmap(self.filehandle.fileno(), self.data_len, mmap.MAP_PRIVATE, mmap.PROT_READ)
        self.offset = 0
        self.delimiter = ", "

        self.formats = {
            'FMT': DFFormat(0x80,
                            'FMT',
                            89,
                            'BBnNZ',
                            "Type,Length,Name,Format,Columns")
        }
        self.id_to_name = { 0x80 : 'FMT' }
        self._rewind()
        self._zero_time_base = zero_time_base
        self.init_clock()
        self._rewind()
        self.init_arrays(progress_callback)

    def _rewind(self):
        '''rewind to start of log'''
        DFReader._rewind(self)
        # find the first valid line
        self.offset = self.data_map.find(b'FMT, ')
        if self.offset == -1:
            self.offset = self.data_map.find(b'FMT,')
            if self.offset != -1:
                self.delimiter = ","
        self.type_list = None

    def rewind(self):
        '''rewind to start of log'''
        self._rewind()

    def init_arrays(self, progress_callback=None):
        '''initialise arrays for fast recv_match()'''
        self.offsets = {}
        self.counts = {}
        self._count = 0
        ofs = self.offset
        pct = 0

        while ofs+16 < self.data_len:
            mtype = self.data_map[ofs:ofs+4]
            # convert to string and cut if there is a ','
            mtype = mtype.decode().split(',')[0]
            if not mtype in self.offsets:
                self.counts[mtype] = 0
                self.offsets[mtype] = []
                self.offset = ofs
                self._parse_next()
            self.offsets[mtype].append(ofs)

            self.counts[mtype] += 1

            if mtype == "FMT":
                self.offset = ofs
                self._parse_next()

            if mtype == "FMTU":
                self.offset = ofs
                self._parse_next()

            ofs = self.data_map.find(b"\n", ofs)
            if ofs == -1:
                break
            ofs += 1
            new_pct = (100 * ofs) // self.data_len
            if progress_callback is not None and new_pct != pct:
                progress_callback(new_pct)
                pct = new_pct

        for mtype in self.counts.keys():
            self._count += self.counts[mtype]
        self.offset = 0

    def skip_to_type(self, type):
        '''skip fwd to next msg matching given type set'''

        if self.type_list is None:
            # always add some key msg types so we can track flightmode, params etc
            self.type_list = type.copy()
            self.type_list.update(set(['MODE','MSG','PARM','STAT','ORGN','VER']))
            self.type_list = list(self.type_list)
            self.indexes = []
            self.type_nums = []
            for t in self.type_list:
                self.indexes.append(0)
        smallest_index = -1
        smallest_offset = self.data_len
        for i in range(len(self.type_list)):
            mtype = self.type_list[i]
            if not mtype in self.counts:
                continue
            if self.indexes[i] >= self.counts[mtype]:
                continue
            ofs = self.offsets[mtype][self.indexes[i]]
            if ofs < smallest_offset:
                smallest_offset = ofs
                smallest_index = i
        if smallest_index >= 0:
            self.indexes[smallest_index] += 1
            self.offset = smallest_offset

    def _parse_next(self):
        '''read one message, returning it as an object'''

        while True:
            endline = self.data_map.find(b'\n',self.offset)
            if endline == -1:
                endline = self.data_len
                if endline < self.offset:
                    break
            s = self.data_map[self.offset:endline].rstrip()
            if sys.version_info.major >= 3:
                s = s.decode('utf-8')
            elements = s.split(self.delimiter)
            self.offset = endline+1
            if len(elements) >= 2:
                # this_line is good
                break

        if self.offset > self.data_len:
            return None

        # cope with empty structures
        if len(elements) == 5 and elements[-1] == ',':
            elements[-1] = ''
            elements.append('')

        self.percent = 100.0 * (self.offset / float(self.data_len))

        msg_type = elements[0]

        if msg_type not in self.formats:
            return self._parse_next()

        fmt = self.formats[msg_type]

        if len(elements) < len(fmt.format)+1:
            # not enough columns
            return self._parse_next()

        elements = elements[1:]

        name = fmt.name.rstrip('\0')
        if name == 'FMT':
            # add to formats
            # name, len, format, headings
            ftype = int(elements[0])
            fname = elements[2]
            if self.delimiter == ",":
                elements = elements[0:4] + [",".join(elements[4:])]
            columns = elements[4]
            if fname == 'FMT' and columns == 'Type,Length,Name,Format':
                # some logs have the 'Columns' column missing from text logs
                columns = "Type,Length,Name,Format,Columns"
            new_fmt = DFFormat(ftype,
                               fname,
                               int(elements[1]),
                               elements[3],
                               columns,
                               oldfmt=self.formats.get(ftype,None))
            self.formats[fname] = new_fmt
            self.id_to_name[ftype] = fname
            self.name_to_id[fname] = ftype

        try:
            m = DFMessage(fmt, elements, False, self)
        except ValueError:
            return self._parse_next()

        if m.get_type() == 'FMTU':
            fmtid = getattr(m, 'FmtType', None)
            if fmtid is not None and fmtid in self.id_to_name:
                fmtu = self.formats[self.id_to_name[fmtid]]
                fmtu.set_unit_ids(getattr(m, 'UnitIds', None), self.unit_lookup)
                fmtu.set_mult_ids(getattr(m, 'MultIds', None), self.mult_lookup)

        if m.get_type() == 'UNIT':
            unitid = getattr(m, 'Id', None)
            label = getattr(m, 'Label', None)
            self.unit_lookup[chr(unitid)] = null_term(label)

        if m.get_type() == 'MULT':
            multid = getattr(m, 'Id', None)
            mult = getattr(m, 'Mult', None)
            # Even though the multiplier value is logged as a double, the
            # values in log files look to be single-precision values that have
            # been cast to a double.
            # To ensure that the values saved here can be used to index the
            # MULT_TO_PREFIX table, we round them to 7 significant decimal digits
            mult = float("%.7g" % (mult))
            self.mult_lookup[chr(multid)] = mult

        self._add_msg(m)

        return m

    def last_timestamp(self):
        '''get the last timestamp in the log'''
        highest_offset = 0
        for mtype in self.counts.keys():
            if len(self.offsets[mtype]) == 0:
                continue
            ofs = self.offsets[mtype][-1]
            if ofs > highest_offset:
                highest_offset = ofs
        self.offset = highest_offset
        m = self.recv_msg()
        return m._timestamp

if __name__ == "__main__":
    use_profiler = False
    if use_profiler:
        from line_profiler import LineProfiler
        profiler = LineProfiler()
        profiler.add_function(DFReader_binary._parse_next)
        profiler.add_function(DFReader_binary._add_msg)
        profiler.add_function(DFReader._set_time)
        profiler.enable_by_count()

    filename = sys.argv[1]
    if filename.endswith('.log'):
        log = DFReader_text(filename)
    else:
        log = DFReader_binary(filename)
    #bfile = filename + ".bin"
    #bout = open(bfile, 'wb')
    while True:
        m = log.recv_msg()
        if m is None:
            break
        #bout.write(m.get_msgbuf())
        #print(m)
    if use_profiler:
        profiler.print_stats()
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [![Build Status](https://travis-ci.org/ArduPilot/pymavlink.svg?branch=master)](https://travis-ci.org/ArduPilot/pymavlink)
# Pymavlink
This is a Python implementation of the MAVLink protocol.
It includes a source code generator (generator/mavgen.py) to create MAVLink protocol implementations for other programming languages as well.
Also contains tools for analyzing flight logs.

# Documentation

Please see http://ardupilot.org/dev/docs/mavlink-commands.html for mavlink command reference.

For realtime discussion please see the pymavlink [Gitter channel](https://gitter.im/ArduPilot/pymavlink)

Examples can be found [in the repository](examples/) or in the [ArduSub book](https://www.ardusub.com/developers/pymavlink.html)


# Installation 

Pymavlink supports both Python 2 and Python 3.

The following instructions assume you are using Python 3 and a Debian-based (like Ubuntu) installation.

.. note::

   pymavlink assumes the command "python" is in your path.  Your distribution may provide a package such as "python-is-python3" to ensure that "python" is in your path.

## Dependencies

Pymavlink has several dependencies :

    - [future](http://python-future.org/) : for Python 2 and Python 3 interoperability
    - [lxml](http://lxml.de/installation.html) : for checking and parsing xml file 

Optional :

    - numpy : for FFT
    - pytest : for tests

### On Linux

lxml has some additional dependencies that can be installed with your package manager (here with `apt-get`) :

.. note::

   If you continue to use Python 2 you may need to change package names here (e.g. python3-numpy => python-numpy)

```bash
sudo apt-get install libxml2-dev libxslt-dev
```

Optional for FFT scripts and tests:

```bash
sudo apt-get install python3-numpy python3-pytest
```

Using pip you can install the required dependencies for pymavlink :

```bash
sudo python -m pip install --upgrade future lxml
```

### On Windows

Use pip to install future as for Linux.
Lxml can be installed with a Windows installer from here : https://pypi.org/project/lxml


## Installation

### For users

It is recommended to install pymavlink from PyPI with pip, that way dependencies should be auto installed by pip.

```bash
sudo python -m pip install --upgrade pymavlink
```

#### Mavnative

Starting from September 2022, mavnative, a C extension for parsing mavlink, was deprecated and removed. Mavnative developpement was stalled for long time, it only supports MAVLink1 and doesn't get any fix on the protocol.

### For developers

From the pymavlink directory, you can use :

```bash
sudo MDEF=PATH_TO_message_definitions python -m pip install . -v
```

Since pip installation is executed from /tmp, it is necessary to point to the directory containing message definitions with MDEF. MDEF should not be set to any particular message version directory but the parent folder instead. If you have cloned from mavlink/mavlink then this is ```/mavlink/message_definitions``` . Using pip should auto install dependencies and allow you to keep them up-to-date. 

Or:

```bash
sudo python setup.py install
```

### Ardupilot Custom Modes

By default, `pymavlink` will map the Ardupilot mode names to mode numbers per the definitions in the [ardupilotmega.xml](https://mavlink.io/en/messages/ardupilotmega.html#PLANE_MODE) file. However, during development, it can be useful to add to or update the default mode mappings.

To do this:
  - create a folder named `.pymavlink` in your home directory (i.e. `$HOME` on Linux, `$USERPROFILE` on Windows); and
  - add a JSON file called `custom_mode_map.json` to this new `.pymavlink` folder.

The JSON file is a dictionary that maps vehicle [`MAV_TYPE`](https://mavlink.io/en/messages/minimal.html#MAV_TYPE) value to a dictionary of mode numbers to mode names. An example that duplicates the existing mapping for `MAV_TYPE_FIXED_WING` (`enum` value of `1`) vehicles is as follows:
```json
{
    "1": {
        "0":  "MANUAL",
        "1":  "CIRCLE",
        "2":  "STABILIZE",
        "3":  "TRAINING",
        "4":  "ACRO",
        "5":  "FBWA",
        "6":  "FBWB",
        "7":  "CRUISE",
        "8":  "AUTOTUNE",
        "10": "AUTO",
        "11": "RTL",
        "12": "LOITER",
        "13": "TAKEOFF",
        "14": "AVOID_ADSB",
        "15": "GUIDED",
        "16": "INITIALISING",
        "17": "QSTABILIZE",
        "18": "QHOVER",
        "19": "QLOITER",
        "20": "QLAND",
        "21": "QRTL",
        "22": "QAUTOTUNE",
        "23": "QACRO",
        "24": "THERMAL"
    }
}
```

This `custom_mode_map.json` file can be used to:
  - change the display name of an existing mode (e.g. change `"TAKEOFF"` to `"LAUNCH"`);
  - add a new mode (e.g. add `"25": "NEW_MODE"`); and
  - add a mapping for an unsupported vehicle type (e.g. add a mapping for `MAV_TYPE_AIRSHIP` (`enum` value of `7`) vehicles).

Notes:
  - Whilst the `MAV_TYPE` and mode numbers are integers, they need to be defined as `string`s in the JSON file, as raw integers can't be used as dictionary keys in JSON.
  - This feature _updates_ the default definitions. You can use it to change the name-to-number mapping for a mode, but you completely can't remove an existing mapping.


# License
---------

pymavlink is released under the GNU Lesser General Public License v3 or later.

The source code generated by generator/mavgen.py is available under the permissive MIT License.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 *.pyc
*~
.lock*
.wafpickle-*
demos/out.txt
waf
build
demos/*/build*
playground/*/build*
.waf-*
.waf3-*
*.log
.DS_Store
.AppleDouble
.LSOverride

# Icon must end with two \r
Icon

# Thumbnails
._*

# Files that might appear in the root of a volume
.DocumentRevisions-V100
.fseventsd
.Spotlight-V100
.TemporaryItems
.Trashes
.VolumeIcon.icns

# Directories potentially created on remote AFP share
.AppleDB
.AppleDesktop
Network Trash Folder
Temporary Items
.apdisk

# Windows build output
waf.bat
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               
pipeline {
    agent none
    stages {
        stage('Build and Lint') {
            parallel {
                stage('Python 2.7') {
                    agent {
                        label "ubuntu"
                    }
                    steps {
                        sh 'python2.7 ./waf-light'
                        stash includes: 'waf', name: 'waf'
                    }
                }
                stage('Python 3.6') {
                    agent {
                        label "freebsd"
                    }
                    steps {
                        sh 'python3.6 ./waf-light'
                    }
                }
                stage('Deprecation warnings') {
                    agent {
                        label "ubuntu"
                    }
                    steps {
                        sh '''
cd waflib
find . -iname "*.pyc" -exec rm -f {} \\; || true
! (((PYTHONWARNINGS=all python3.6 -m compileall . > /dev/null) 2>&1 ) 2>&1) | grep -i DeprecationWarning
'''
                    }
                }
                stage('Pyflakes') {
                    agent {
                        label "freebsd"
                    }
                    steps {
                        sh '''
cd waflib
var=`(/usr/local/bin/pyflakes3.py *.py Tools/*.py extras/*.py 2>&1) | egrep "undefined name|invalid syntax|inconsistent use|unindent does not match any outer indentation level" | wc -l`
if [ "0" -eq "$var" ]
then
   /usr/local/bin/pyflakes3.py *.py Tools/*.py extras/*.py || true
else
   # just do it again and fail
   /usr/local/bin/pyflakes3.py *.py Tools/*.py extras/*.py
   exit 1
fi
'''
                    }
                }
                stage('Unit tests') {
                    agent {
                        label "fedora"
                    }
                    steps {
                        sh '''
./waf-light
cd tests/preproc/
../../waf distclean
../../waf configure build
cd ../..'''
                        sh '''
cd tests/install/
../../waf distclean
../../waf configure build
cd ../..'''
                        sh '''
cd tests/general/
../../waf distclean
../../waf configure build
cd ../..'''
                        sh '''
export PATH=$PATH:$PWD
cd tests/init/
../../waf distclean
../../waf configure build
cd ../..'''
                        sh '''
export WAF_TEST_GROUP=waftest
cd tests/install_group/
../../waf distclean
../../waf configure build
'''
                    }
                }
            }
        }
        stage('Integration') {
            parallel {
                stage('Ubuntu') {
                    stages {
                        stage('py25') {
                            agent {
                                label "ubuntu"
                            }
                            steps {
                                dir('demos') {
                                        unstash 'waf'
                                }
                                sh '''cd demos; LD_LIBRARY_PATH=/opt/lib ./waf distclean configure clean build --top=c'''
                                sh '''cd demos; LD_LIBRARY_PATH=/opt/lib ./waf distclean configure clean build --top=c++'''
                                sh '''cd demos; LD_LIBRARY_PATH=/opt/lib ./waf distclean configure clean build --top=java'''
                                sh '''cd demos; LD_LIBRARY_PATH=/opt/lib ./waf distclean configure clean build --top=perl'''
                                sh '''cd demos; LD_LIBRARY_PATH=/opt/lib ./waf distclean configure clean build --top=python'''
                                sh '''cd demos; LD_LIBRARY_PATH=/opt/lib ./waf distclean configure clean build --top=qt5'''
                                sh '''cd demos; LD_LIBRARY_PATH=/opt/lib ./waf distclean configure clean build --top=subst'''
                            }
                        }
                        stage('py36') {
                            agent {
                                label "ubuntu"
                            }
                            steps {
                                dir('demos') {
                                    unstash 'waf'
                                }
                                sh '''cd demos; python3 ./waf configure clean build --top=c'''
                                sh '''cd demos; python3 ./waf configure clean build --top=c++'''
                                sh '''cd demos; python3 ./waf configure clean build --top=java'''
                                sh '''cd demos; python3 ./waf configure clean build --top=perl'''
                                sh '''cd demos; python3 ./waf configure clean build --top=python'''
                                sh '''cd demos; python3 ./waf configure clean build --top=qt5'''
                                sh '''cd demos; python3 ./waf configure clean build --top=subst'''
                            }
                        }
                        stage('py27') {
                            agent {
                                label "ubuntu"
                            }
                            steps {
                                dir('demos') {
                                    unstash 'waf'
                                }
                                sh '''cd demos; ./waf configure clean build --top=c'''
                                sh '''cd demos; ./waf configure clean build --top=c++'''
                                sh '''cd demos; ./waf configure clean build --top=java'''
                                sh '''cd demos; ./waf configure clean build --top=perl'''
                                sh '''cd demos; ./waf configure clean build --top=python'''
                                sh '''cd demos; ./waf configure clean build --top=qt5'''
                                sh '''cd demos; ./waf configure clean build --top=subst'''
                            }
                        }
                    }
                }
                stage('OpenBSD') {
                    stages {
                        stage('Jython') {
                            agent {
                                label "openbsd"
                            }
                            steps {
                                sh '''
        export WAF_NO_PREFORK=1
        /home/jenkins/jython/bin/jython ./waf-light
        cp waf demos/c
        cd demos/c
        /home/jenkins/jython/bin/jython ./waf distclean configure clean build
        '''
                            }
                        }
                        stage('py38') {
                            agent {
                                label "openbsd"
                            }
                            steps {
                                dir('demos') {
                                    unstash 'waf'
                                }
                                sh '''cd demos/asm; python3 ../waf configure clean build'''
                                sh '''cd demos/c; python3 ../waf configure clean build'''
                                sh '''cd demos/c++; python3 ../waf configure clean build'''
                                sh '''cd demos/glib2; python3 ../waf configure clean build'''
                                sh '''cd demos/perl; python3 ../waf configure clean build'''
                                sh '''cd demos/python; python3 ../waf configure clean build'''
                                sh '''cd demos/subst; python3 ../waf configure clean build'''
                            }
                        }
                    }
                }
                stage('Windows') {
                    stages {
                        stage('C/py34') {
                            agent {
                                label "windows"
                            }
                            steps {
                                bat ''' C:/Python34/python.exe waf-light --tools=msvs '''
                                bat '''
        copy waf demos\\c /Y
        cd demos\\c
        C:/Python34/python.exe waf distclean
        C:/Python34/python.exe waf configure --no-msvc-lazy build -v
        '''
                                bat '''
        copy waf demos\\qt5 /Y
        cd demos\\qt5
        C:/Python34/python.exe waf distclean
        C:/Python34/python.exe waf configure --no-msvc-lazy build -v
        '''
                                bat '''
        copy waf playground\\msvs /Y
        cd playground\\msvs
        C:/Python34/python.exe waf distclean
        C:/Python34/python.exe waf configure
        C:/Python34/python.exe waf msvs
        '''
                            }
                        }
                        stage('C/Msys2/py27') {
                            agent {
                                label "windows"
                            }
                            steps {
                                unstash 'waf'
                                bat '''
        copy waf demos\\c /Y
        cd demos\\c
        set MSYSTEM=MINGW64
        set WD=C:\\msys64\\usr\\bin
        set CHERE_INVOKING=1
        C:\\msys64\\usr\\bin\\sh --login -c 'exec /bin/bash -c "python waf configure clean build && python waf distclean"'
        '''
                            }
                        }
                        stage('C/Msys2/py35') {
                            agent {
                                label "windows"
                            }
                            steps {
                                unstash 'waf'
                                bat '''
        copy waf demos\\c /Y
        cd demos\\c
        set MSYSTEM=MINGW64
        set WD=C:\\msys64\\usr\\bin
        set CHERE_INVOKING=1
        C:\\msys64\\usr\\bin\\sh --login -c 'exec /bin/bash -c "python3 waf configure clean build && python3 waf distclean"'
        '''
                            }
                        }
                    }
                }
                stage('FreeBSD') {
                    stages {
                        stage('py36') {
                            agent {
                                label "freebsd"
                            }
                            steps {
                                dir('demos') {
                                    unstash 'waf'
                                }
                                sh '''cd demos/c; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/c++; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/java; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/jni; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/perl; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/python; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/ruby; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/glib2; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/qt5; python3.6 ../waf distclean configure clean build'''
                                sh '''cd demos/dbus; python3.6 ../waf distclean configure clean build'''
                            }
                        }
                    }
                }
                stage('MacOS') {
                    stages {
                        stage('py27') {
                            agent {
                                label "macos"
                            }
                            steps {
                                dir('demos') {
                                    unstash 'waf'
                                }
                                sh '''cd demos/c; ../waf distclean configure clean build'''
                                sh '''cd demos/python; ../waf distclean configure clean build'''
                                sh '''cd demos/mac_app; ../waf distclean configure clean build'''
                            }
                        }
                    }
                }
            }
        }
    }
}
   NEW IN WAF 2.0.27
-----------------
* Improve Qt6 detection on msvc #2423
* Fix a regression in the detection of QtX3D libraries #2367
* Avoid coloring all MSVC logs #2366
* Switch to nonstopmode for latex prompts #2421
* Restrict executable detection to files having the executable bits #2349

NEW IN WAF 2.0.26
-----------------
* Improve "waf dist" - Support SOURCE_DATE_EPOCH
* Detect Qt6 #2355
* Haxe toolkit support #2352
* Updated the project's gpg key

NEW IN WAF 2.0.25
-----------------
* Fix invalid characters returned by find_program #2397
* Prepare for distutils removal (Python 3.12 regression) #2402
* Improve cp65001 compat in cpython < 3.3 #2346
* Add Fujitsu Fortran compiler detection on ARM64FX #2348
* Support multiple Sphinx output formats #2344
* Improve PyQt5 detection #2343
* Add asynchronous wafcache uploads

NEW IN WAF 2.0.24
-----------------
* Use EXT_SUFFIX config var over the deprecated/removed SO (Python 3.11 regression) #2386
* When detecting Visual Studio compilers, prefer the oldest version regardless of compiler type #2352
* Update the MacOS-specific examples #2337
* Fix Configure.find_program() invalid character handling in default variable names #2397

NEW IN WAF 2.0.23
-----------------
* Fix the Qt3D* libraries detection #2368
* Fix swig processing when \r is preset in the module name #2350
* Add RISC-V generic detection #2322
* Detect gcc first on GNU/kFreeBSD #2336
* Improve waflib/extras/msvcdeps performance #2323

NEW IN WAF 2.0.22
-----------------
* Fix stdin propagation with faulty vcvarsall scripts #2315
* Enable mixing Unix-style paths with destdir on Windows platforms #2337
* Fix shell escaping unit test parameters #2314
* Improve extras/clang_compilation_database and extras/swig compatibility #2336
* Propagate C++ flags to the Cuda compiler in extras/cuda #2311
* Fix detection of Qt 5.0.0 (preparation for Qt6) #2331
* Enable Haxe processing #2308
* Fix regression in MACOSX_DEPLOYMENT_TARGET caused by distutils #2330
* Fix extras/wafcache concurrent trimming issues #2312
* Fix extras/wafcache symlink handling #2327

NEW IN WAF 2.0.21
-----------------
* Set the default --msvc_version from VSCMD_VER if present #2299
* Force unit-test reruns on ut_str, ut_cmd or ut_path changes #2302
* Describe Qt5's library detection #2288
* Introduce conf.env.ASMDEFINES_ST to enable assembly-specific define flags
* Update extras/xcode6 to Python3 #2290
* Enable parameter "always" in extras/doxygen #2292
* Fix extras/c_dumbpreproc as it was previously broken
* Fix extras/gccdeps and extras/msvcdeps on header renaming #2293
* Improve extras/msvcdeps debug outputs and flags #2287 #2291
* Add add MCST Elbrus CPU detection in c config #2297
* Add minio object copies to extras/wafcache #2304

NEW IN WAF 2.0.20
-----------------
* Detect -flto and -fno-lto in parse_config #2281
* Improve custom option processing #2280
* Enable Clang on cygwin #2279
* Make distclean target 'no_lock_in_top/run' modifiers compatible with env vars #2271
* Update irix compiler detection
* Exclude ConfigSet from altering ConfigurationContext.run_build caches #2273
* Add gas support in extras/gccdeps.py #2278
* Improve compatibility with custom commands in extras/clang_compilation_database #2274

NEW IN WAF 2.0.19
-----------------
* Enable race-free pdb file generation waflib/extras/msvc_pdb.py #1731
* Fix negative values for -j #2256
* Fix Swig example compatibility with Python3 #2259
* Fix lto settings for endianness configuration tests #2250
* Tune the application name on --help #2254
* Improve Qt5's fPIC/fPIE detection
* Propagate LDFLAGS to Fortran tasks (in addition to LINKFLAGS)
* Enable local and remote build object caches waflib/extras/wafcache.py

NEW IN WAF 2.0.18
-----------------
* Fix a deadlock with cython and subst tasks #2244
* Fix rpath processing so that it no longer breaks dependency chains
* Fix fast_partial.py failures on configuration tests
* Fix duplicate -fno-strict-aliasing flags in Python compilation flags detection
* Fix annoying PIE errors in demos/asm/
* Improve configuration tests cache accuracy #2251
* Improve extras/fast_partial.py compatibility
* Improve extras/doxygen.py outdir parameter settings #2255
* Add a dependency scanner for assembly files (Gas/Yasm)
* Add executable arguments for configuration tests / execute=True
* Add a QtTest example to demos/qt5/ #2241
* Add a cross-compilation option to extras/objcopy.py #2247

NEW IN WAF 2.0.17
-----------------
* Improve build performance on FreeBSD and Python3 #2241
* Add Python 3.8 flag detection for building embedded interpreters #2239
* Prevent Qt5 uninstallation errors when c++ files are generated
* Improve installation/uninstallation colors

NEW IN WAF 2.0.16
-----------------
* Fix task semaphore errors on stateful tasks #2232
* Fix encoding errors with UTF-8 paths on Python 2 #2230
* Fix encoding errors in waf_unit_test #2220
* Improve dependency between javac task and use-d generated jars nodes
* Install pdb files with /debug:* flags #2224
* Make javadoc detection optional #2225
* Improve md5_tstamp documentation #2221
* Add extras/color_msvc to colorizes MSVC outputs #2221
* Fix symbol regex on mac-o binaries in extras/syms #2222
* Maintain order of lines in doxyfile in extras/doxygen #2223
* Improve extras/msvcdeps path handling
* Add extras/clang_cross for cross-compilation using clang

NEW IN WAF 2.0.15
-----------------
* Fix Python path detection under Git-Bash #2217
* Provide an option to disable args files #2216
* Improve command line length calculation for args files #2214
* Add libs/stubs to Cuda library path #2213
* Suppress ant_glob java warnings #2212
* Support multiple 'default_cmd' #2211
* Warn when buildcopy is used without any files to copy #2210
* Protobuf examples enhancements #2208 #2209
* Fix all DeprecationWarning: invalid escape sequence #2207

NEW IN WAF 2.0.14
-----------------
* Support Fortran 2008 submodules #2205
* Possible solution for Msys/Python 3.6 path issues #2217
* Support NEC SX-Aurora TSUBASA system's Fortran compiler extras/fc_nfort.py #2206
* Fix ignored configuration flags in gccdeps extras/gccdeps.py #2203
* Fix included protoc search on nested wscripts extras/protoc.py #2202
* Support extra taskgen and out of project include directories extras/protoc.py #2204

NEW IN WAF 2.0.13
-----------------
* Fix "broken revdeps" extra error message on certain build failures
* Avoid duplicate flags in Python configuration tests
* Find more Swig dependencies #2206
* Avoid spawning threads with -j1 on AIX systems

NEW IN WAF 2.0.12
-----------------
* Fix broken inheritance task trees #2194

NEW IN WAF 2.0.11
-----------------
* Do not raise an exception on check_cfg/mandatory=False/-vv #2193
* Post past task generators in lazy sub-folder builds #2191
* Disable warnings on versioned library installation
* Fix cpplint concurrent execution problems

NEW IN WAF 2.0.10
-----------------
* Add a task semaphore system
* Fix --help when no wscript is supplied #2184
* Fix Fortran processing with generated Fortran files

NEW IN WAF 2.0.9
----------------
* Add dependencies on scriptlet outputs
* Made options optional for cython waftool
* Improve doxygen error handling

NEW IN WAF 2.0.8
----------------
* Improve Windows console encoding outputs on Python 3.6 and Japanese code page #2163
* Improve msvc detection on Python 3.6 and Japanese code page #2155
* Improve moc/rcc flag parsing with msvc #2169
* Improve Eclipse project generation #2166 #2165 #2164 #2149 #2145
* Improve Boost project detection on dpkg-based systems #2146

NEW IN WAF 2.0.7
----------------
* Apply priorities to dynamically-generated tasks #2137
* Fix upcoming Python 3.7 incompatibilities #2126
* Fix Python3 support in extras/xcode6.py #2121
* Improve priority support in extras/swig.py #2137
* Improve support extras/protoc.py #2135
* Improve argument handling in extras/clang_compilation_database.py #2127
* Add glib DBus bindings in extras/gdbus.py #2134
* Avoid name collisions for precompiled headers and libraries with similar names in extras/pch.py #2122

NEW IN WAF 2.0.6
----------------
* Add Task.deep_inputs to enable further dependencies on input file tasks
* Set unit tests to depend on input file tasks instead of timestamps

NEW IN WAF 2.0.5
----------------
* Force unit tests to depend on the executable creation time besides file contents
* Enhance the Eclipse project generator
* Update the cuda examples

NEW IN WAF 2.0.4
----------------
* Enable more advanced warnings of ant_glob on build folders in verbose mode
* Defer node.ant_glob(..., generator=True) evaluation
* Enable 'waf clean' to get the list of files to remove from bld.clean_files
* Define the environment variable WAF_NO_PREFORK to skip pre-forking
* Fix Can't pickle local object '_createenviron.<locals>.encode' exceptions (Python 3.6)
* Improve the Erlang module #2095
* Add task target to parallel_debug outputs #2091

NEW IN WAF 2.0.3
----------------
* Enable install_path=None for Python targets #2087
* Skip empty or duplicates in java user classpath #2084
* Change the unit test summary color scheme to use green and red colors
* Improve the deadlock error message
* Report sys.path values from Context.load_tool to improve error messages
* Cache qrc uic->h conversions to enable qrc re-use across targets
* Output long-running tasks outputs immediately using bld(rule=..., stdout=None)

NEW IN WAF 2.0.2
----------------
* Improve Intel Fortran compiler detection on Windows #2063
* Ensure that the task count starts at 1 in the build outputs
* Add a --pdb option to start pdb on unexpected exceptions #2052
* Fix conflicting qm/qrc re-used output files for multiple targets #2065
* Add java support in protobuf (extras) #2049
* Add a java test example (extras) #2062
* Enable symbol processing for empty targets (extras) #2053

NEW IN WAF 2.0.1
----------------
* Improve the default preprocessor behaviour for gcc/msvc
* Accept task objects in Build.add_to_group for compatibility reasons
* Prevent xcode generator from overwriting existing features #2038
* Fix self.includes data scope #2035
* Fix Node.ant_glob case sensitivity regression #2034
* Fix Logs.verbose options regression #2033

NEW IN WAF 2.0.0
----------------
* Provide a new priority system to improve scalability on complex builds
* Provide TaskGroup objects to improve scalability on complex builds
* Force new files into the build directory by default (use Node objects to bypass)
* Provide built-in support for building over UNC paths
* Simplify the Task class hierarchy; TaskBase is removed
* Display commands as string with "WAF_CMD_FORMAT=string waf build -v"
* Have ant_glob(..., generator=True) return a Python generator
* Accept nested lists and generators in bld(source=...)
* Sort TaskGen methods in alphabetical order by reversing TaskGen.prec order

* Remove 'ut_fun' from waf_unit_test.py
* Remove Node.sig and Node.cache_sig
* Remove the BuildContext.rule decorator
* Remove Task.update_outputs, Task.always_run
* Remove atleast-version, exact-version and max-version from conf.check_cfg
* Remove c_preproc.trimquotes
* Remove field_name, type_name, function_name from conf.check() tests
* Remove extras/mem_reducer.py as a better solution has been merged
* Remove Utils.ex_stack (use traceback.format_exc())
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Waf 2.0 is on https://gitlab.com/ita1024/waf
------------------------------------------------

waflib            the core library
waflib/Tools      essential waf tools
waflib/extras     contributed tools which are not included in the waf file by default
build_system_kit  examples of build systems that can be created from Waf
tests             various unit tests, most are unused anymore
playground        experimental examples and test, most tools lie in the folder waflib/extras
demos             integration tests - the folder can be configured as a standalone project
demos/*           integration tests and examples used as documentation
docs              documentation
docs/sphinx       project extracting the docstrings from the source code to create the API documentation

Documentation
-------------------------------------------------

API documentation        https://waf.io/apidocs/
The Waf Book             https://waf.io/book/

General coding guidelines
-------------------------

* The code must run in both Python 2.6 to Python 3
* Use tabs for Python file indentation
* Use x.splitlines() instead of x.split('\n')
* Avoid "except:" and "except Exception:"
* Use Node.readf/Node.writef/Utils.readf/Utils.writef

Pull requests
-------------

See https://gitlab.com/ita1024/waf

When implementing complex features, please add examples in the showcase folder demos/
for modules under waflib/Tools, under tests/ for platform-independent unit tests,
or in playground/ for modules under waflib/extras.

The files under waflib/Tools/ are kept API-compatible for the duration
of a middle version (currently 2.0).

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         # vim:syntax=python

exts = [x+'.dll' for x in 'WixNetFxExtension WixUIExtension WixBalExtension WixUtilExtension'.split()]

funi = ctx.env['dllname']
funigui = ctx.env['guiname']
funiversion = ctx.env['version']
funivisiblename = funigui+'_'+funiversion
funimsi = funivisiblename+'.msi'
funicompany = ctx.env['company']

define=lambda v:'-d'+v+'='+eval(v)
wixvar = [define(v) for v in 'funi funigui funimsi funivisiblename funiversion funicompany'.split()]

bld(features = 'wix', source=['funi.wxs']+exts , gen=funimsi, candleflags=wixvar)
bld.add_group()
bld(features = 'wix', source=['bundle.wxs']+exts, gen='setup.exe', candleflags=wixvar)

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           #!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2006-2018 (ita)
# Ralf Habacker, 2006 (rh)
# Yinon Ehrlich, 2009
# Michael Kuhn, 2009

from waflib.Tools import ccroot, ar
from waflib.Configure import conf

@conf
def find_xlcxx(conf):
	"""
	Detects the Aix C++ compiler
	"""
	cxx = conf.find_program(['xlc++_r', 'xlc++'], var='CXX')
	conf.get_xlc_version(cxx)
	conf.env.CXX_NAME = 'xlc++'

@conf
def xlcxx_common_flags(conf):
	"""
	Flags required for executing the Aix C++ compiler
	"""
	v = conf.env

	v.CXX_SRC_F           = []
	v.CXX_TGT_F           = ['-c', '-o']

	if not v.LINK_CXX:
		v.LINK_CXX = v.CXX

	v.CXXLNK_SRC_F        = []
	v.CXXLNK_TGT_F        = ['-o']
	v.CPPPATH_ST          = '-I%s'
	v.DEFINES_ST          = '-D%s'

	v.LIB_ST              = '-l%s' # template for adding libs
	v.LIBPATH_ST          = '-L%s' # template for adding libpaths
	v.STLIB_ST            = '-l%s'
	v.STLIBPATH_ST        = '-L%s'
	v.RPATH_ST            = '-Wl,-rpath,%s'

	v.SONAME_ST           = []
	v.SHLIB_MARKER        = []
	v.STLIB_MARKER        = []

	v.LINKFLAGS_cxxprogram= ['-Wl,-brtl']
	v.cxxprogram_PATTERN  = '%s'

	v.CXXFLAGS_cxxshlib   = ['-fPIC']
	v.LINKFLAGS_cxxshlib  = ['-G', '-Wl,-brtl,-bexpfull']
	v.cxxshlib_PATTERN    = 'lib%s.so'

	v.LINKFLAGS_cxxstlib  = []
	v.cxxstlib_PATTERN    = 'lib%s.a'

def configure(conf):
	conf.find_xlcxx()
	conf.find_ar()
	conf.xlcxx_common_flags()
	conf.cxx_load_tools()
	conf.cxx_add_flags()
	conf.link_add_flags()

                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    #!/usr/bin/env python
# encoding: utf-8
# Thomas Nagy, 2005-2018 (ita)

"""
Utilities and platform-specific fixes

The portability fixes try to provide a consistent behavior of the Waf API
through Python versions 2.5 to 3.X and across different platforms (win32, linux, etc)
"""

from __future__ import with_statement

import atexit, os, sys, errno, inspect, re, datetime, platform, base64, signal, functools, time, shlex

try:
	import cPickle
except ImportError:
	import pickle as cPickle

# leave this
if os.name == 'posix' and sys.version_info[0] < 3:
	try:
		import subprocess32 as subprocess
	except ImportError:
		import subprocess
else:
	import subprocess

try:
	TimeoutExpired = subprocess.TimeoutExpired
except AttributeError:
	class TimeoutExpired(Exception):
		pass

from collections import deque, defaultdict

try:
	import _winreg as winreg
except ImportError:
	try:
		import winreg
	except ImportError:
		winreg = None

from waflib import Errors

try:
	from hashlib import md5
except ImportError:
	try:
		from hashlib import sha1 as md5
	except ImportError:
		# never fail to enable potential fixes from another module
		pass
else:
	try:
		md5().digest()
	except ValueError:
		# Fips? #2213
		from hashlib import sha1 as md5

try:
	import threading
except ImportError:
	if not 'JOBS' in os.environ:
		# no threading :-(
		os.environ['JOBS'] = '1'

	class threading(object):
		"""
		A fake threading class for platforms lacking the threading module.
		Use ``waf -j1`` on those platforms
		"""
		pass
	class Lock(object):
		"""Fake Lock class"""
		def acquire(self):
			pass
		def release(self):
			pass
	threading.Lock = threading.Thread = Lock

SIG_NIL = 'SIG_NIL_SIG_NIL_'.encode()
"""Arbitrary null value for hashes. Modify this value according to the hash function in use"""

O644 = 420
"""Constant representing the permissions for regular files (0644 raises a syntax error on python 3)"""

O755 = 493
"""Constant representing the permissions for executable files (0755 raises a syntax error on python 3)"""

rot_chr = ['\\', '|', '/', '-']
"List of characters to use when displaying the throbber (progress bar)"

rot_idx = 0
"Index of the current throbber character (progress bar)"

class ordered_iter_dict(dict):
	"""Ordered dictionary that provides iteration from the most recently inserted keys first"""
	def __init__(self, *k, **kw):
		self.lst = deque()
		dict.__init__(self, *k, **kw)
	def clear(self):
		dict.clear(self)
		self.lst = deque()
	def __setitem__(self, key, value):
		if key in dict.keys(self):
			self.lst.remove(key)
		dict.__setitem__(self, key, value)
		self.lst.append(key)
	def __delitem__(self, key):
		dict.__delitem__(self, key)
		try:
			self.lst.remove(key)
		except ValueError:
			pass
	def __iter__(self):
		return reversed(self.lst)
	def keys(self):
		return reversed(self.lst)

class lru_node(object):
	"""
	Used by :py:class:`waflib.Utils.lru_cache`
	"""
	__slots__ = ('next', 'prev', 'key', 'val')
	def __init__(self):
		self.next = self
		self.prev = self
		self.key = None
		self.val = None

class lru_cache(object):
	"""
	A simple least-recently used cache with lazy allocation
	"""
	__slots__ = ('maxlen', 'table', 'head')
	def __init__(self, maxlen=100):
		self.maxlen = maxlen
		"""
		Maximum amount of elements in the cache
		"""
		self.table = {}
		"""
		Mapping key-value
		"""
		self.head = lru_node()
		self.head.next = self.head
		self.head.prev = self.head

	def __getitem__(self, key):
		node = self.table[key]
		# assert(key==node.key)
		if node is self.head:
			return node.val

		# detach the node found
		node.prev.next = node.next
		node.next.prev = node.prev

		# replace the head
		node.next = self.head.next
		node.prev = self.head
		self.head = node.next.prev = node.prev.next = node

		return node.val

	def __setitem__(self, key, val):
		if key in self.table:
			# update the value for an existing key
			node = self.table[key]
			node.val = val
			self.__getitem__(key)
		else:
			if len(self.table) < self.maxlen:
				# the very first item is unused until the maximum is reached
				node = lru_node()
				node.prev = self.head
				node.next = self.head.next
				node.prev.next = node.next.prev = node
			else:
				node = self.head = self.head.next
				try:
					# that's another key
					del self.table[node.key]
				except KeyError:
					pass

			node.key = key
			node.val = val
			self.table[key] = node

class lazy_generator(object):
	def __init__(self, fun, params):
		self.fun = fun
		self.params = params

	def __iter__(self):
		return self

	def __next__(self):
		try:
			it = self.it
		except AttributeError:
			it = self.it = self.fun(*self.params)
		return next(it)

	next = __next__

is_win32 = os.sep == '\\' or sys.platform == 'win32' or os.name == 'nt' # msys2
"""
Whether this system is a Windows series
"""

def readf(fname, m='r', encoding='latin-1'):
	"""
	Reads an entire file into a string. See also :py:meth:`waflib.Node.Node.readf`::

		def build(ctx):
			from waflib import Utils
			txt = Utils.readf(self.path.find_node('wscript').abspath())
			txt = ctx.path.find_node('wscript').read()

	:type  fname: string
	:param fname: Path to file
	:type  m: string
	:param m: Open mode
	:type encoding: string
	:param encoding: encoding value, only used for python 3
	:rtype: string
	:return: Content of the file
	"""

	if sys.hexversion > 0x3000000 and not 'b' in m:
		m += 'b'
		with open(fname, m) as f:
			txt = f.read()
		if encoding:
			txt = txt.decode(encoding)
		else:
			txt = txt.decode()
	else:
		with open(fname, m) as f:
			txt = f.read()
	return txt

def writef(fname, data, m='w', encoding='latin-1'):
	"""
	Writes an entire file from a string.
	See also :py:meth:`waflib.Node.Node.writef`::

		def build(ctx):
			from waflib import Utils
			txt = Utils.writef(self.path.make_node('i_like_kittens').abspath(), 'some data')
			self.path.make_node('i_like_kittens').write('some data')

	:type  fname: string
	:param fname: Path to file
	:type   data: string
	:param  data: The contents to write to the file
	:type  m: string
	:param m: Open mode
	:type encoding: string
	:param encoding: encoding value, only used for python 3
	"""
	if sys.hexversion > 0x3000000 and not 'b' in m:
		data = data.encode(encoding)
		m += 'b'
	with open(fname, m) as f:
		f.write(data)

def h_file(fname):
	"""
	Computes a hash value for a file by using md5. Use the md5_tstamp
	extension to get faster build hashes if necessary.

	:type fname: string
	:param fname: path to the file to hash
	:return: hash of the file contents
	:rtype: string or bytes
	"""
	m = md5()
	with open(fname, 'rb') as f:
		while fname:
			fname = f.read(200000)
			m.update(fname)
	return m.digest()

def readf_win32(f, m='r', encoding='latin-1'):
	flags = os.O_NOINHERIT | os.O_RDONLY
	if 'b' in m:
		flags |= os.O_BINARY
	if '+' in m:
		flags |= os.O_RDWR
	try:
		fd = os.open(f, flags)
	except OSError:
		raise IOError('Cannot read from %r' % f)

	if sys.hexversion > 0x3000000 and not 'b' in m:
		m += 'b'
		with os.fdopen(fd, m) as f:
			txt = f.read()
		if encoding:
			txt = txt.decode(encoding)
		else:
			txt = txt.decode()
	else:
		with os.fdopen(fd, m) as f:
			txt = f.read()
	return txt

def writef_win32(f, data, m='w', encoding='latin-1'):
	if sys.hexversion > 0x3000000 and not 'b' in m:
		data = data.encode(encoding)
		m += 'b'
	flags = os.O_CREAT | os.O_TRUNC | os.O_WRONLY | os.O_NOINHERIT
	if 'b' in m:
		flags |= os.O_BINARY
	if '+' in m:
		flags |= os.O_RDWR
	try:
		fd = os.open(f, flags)
	except OSError:
		raise OSError('Cannot write to %r' % f)
	with os.fdopen(fd, m) as f:
		f.write(data)

def h_file_win32(fname):
	try:
		fd = os.open(fname, os.O_BINARY | os.O_RDONLY | os.O_NOINHERIT)
	except OSError:
		raise OSError('Cannot read from %r' % fname)
	m = md5()
	with os.fdopen(fd, 'rb') as f:
		while fname:
			fname = f.read(200000)
			m.update(fname)
	return m.digest()

# always save these
readf_unix = readf
writef_unix = writef
h_file_unix = h_file
if hasattr(os, 'O_NOINHERIT') and sys.hexversion < 0x3040000:
	# replace the default functions
	readf = readf_win32
	writef = writef_win32
	h_file = h_file_win32

try:
	x = ''.encode('hex')
except LookupError:
	import binascii
	def to_hex(s):
		ret = binascii.hexlify(s)
		if not isinstance(ret, str):
			ret = ret.decode('utf-8')
		return ret
else:
	def to_hex(s):
		return s.encode('hex')

to_hex.__doc__ = """
Return the hexadecimal representation of a string

:param s: string to convert
:type s: string
"""

def listdir_win32(s):
	"""
	Lists the contents of a folder in a portable manner.
	On Win32, returns the list of drive letters: ['C:', 'X:', 'Z:'] when an empty string is given.

	:type s: string
	:param s: a string, which can be empty on Windows
	"""
	if not s:
		try:
			import ctypes
		except ImportError:
			# there is nothing much we can do
			return [x + ':\\' for x in 'ABCDEFGHIJKLMNOPQRSTUVWXYZ']
		else:
			dlen = 4 # length of "?:\\x00"
			maxdrives = 26
			buf = ctypes.create_string_buffer(maxdrives * dlen)
			ndrives = ctypes.windll.kernel32.GetLogicalDriveStringsA(maxdrives*dlen, ctypes.byref(buf))
			return [ str(buf.raw[4*i:4*i+2].decode('ascii')) for i in range(int(ndrives/dlen)) ]

	if len(s) == 2 and s[1] == ":":
		s += os.sep

	if not os.path.isdir(s):
		e = OSError('%s is not a directory' % s)
		e.errno = errno.ENOENT
		raise e
	return os.listdir(s)

listdir = os.listdir
if is_win32:
	listdir = listdir_win32

def num2ver(ver):
	"""
	Converts a string, tuple or version number into an integer. The number is supposed to have at most 4 digits::

		from waflib.Utils import num2ver
		num2ver('1.3.2') == num2ver((1,3,2)) == num2ver((1,3,2,0))

	:type ver: string or tuple of numbers
	:param ver: a version number
	"""
	if isinstance(ver, str):
		ver = tuple(ver.split('.'))
	if isinstance(ver, tuple):
		ret = 0
		for i in range(4):
			if i < len(ver):
				ret += 256**(3 - i) * int(ver[i])
		return ret
	return ver

def to_list(val):
	"""
	Converts a string argument to a list by splitting it by spaces.
	Returns the object if not a string::

		from waflib.Utils import to_list
		lst = to_list('a b c d')

	:param val: list of string or space-separated string
	:rtype: list
	:return: Argument converted to list
	"""
	if isinstance(val, str):
		return val.split()
	else:
		return val

def console_encoding():
	try:
		import ctypes
	except ImportError:
		pass
	else:
		try:
			codepage = ctypes.windll.kernel32.GetConsoleCP()
		except AttributeError:
			pass
		else:
			if codepage:
				if 65001 == codepage and sys.version_info < (3, 3):
					return 'utf-8'
				return 'cp%d' % codepage
	return sys.stdout.encoding or ('cp1252' if is_win32 else 'latin-1')

def split_path_unix(path):
	return path.split('/')

def split_path_cygwin(path):
	if path.startswith('//'):
		ret = path.split('/')[2:]
		ret[0] = '/' + ret[0]
		return ret
	return path.split('/')

re_sp = re.compile('[/\\\\]+')
def split_path_win32(path):
	if path.startswith('\\\\'):
		ret = re_sp.split(path)[1:]
		ret[0] = '\\\\' + ret[0]
		if ret[0] == '\\\\?':
			return ret[1:]
		return ret
	return re_sp.split(path)

msysroot = None
def split_path_msys(path):
	if path.startswith(('/', '\\')) and not path.startswith(('//', '\\\\')):
		# msys paths can be in the form /usr/bin
		global msysroot
		if not msysroot:
			# msys has python 2.7 or 3, so we can use this
			msysroot = subprocess.check_output(['cygpath', '-w', '/']).decode(sys.stdout.encoding or 'latin-1')
			msysroot = msysroot.strip()
		path = os.path.normpath(msysroot + os.sep + path)
	return split_path_win32(path)

if sys.platform == 'cygwin':
	split_path = split_path_cygwin
elif is_win32:
	# Consider this an MSYSTEM environment if $MSYSTEM is set and python
	# reports is executable from a unix like path on a windows host.
	if os.environ.get('MSYSTEM') and sys.executable.startswith('/'):
		split_path = split_path_msys
	else:
		split_path = split_path_win32
else:
	split_path = split_path_unix

split_path.__doc__ = """
Splits a path by / or \\; do not confuse this function with with ``os.path.split``

:type  path: string
:param path: path to split
:return:     list of string
"""

def check_dir(path):
	"""
	Ensures that a directory exists (similar to ``mkdir -p``).

	:type  path: string
	:param path: Path to directory
	:raises: :py:class:`waflib.Errors.WafError` if the folder cannot be added.
	"""
	if not os.path.isdir(path):
		try:
			os.makedirs(path)
		except OSError as e:
			if not os.path.isdir(path):
				raise Errors.WafError('Cannot create the folder %r' % path, ex=e)

def check_exe(name, env=None):
	"""
	Ensures that a program exists

	:type name: string
	:param name: path to the program
	:param env: configuration object
	:type env: :py:class:`waflib.ConfigSet.ConfigSet`
	:return: path of the program or None
	:raises: :py:class:`waflib.Errors.WafError` if the folder cannot be added.
	"""
	if not name:
		raise ValueError('Cannot execute an empty string!')
	def is_exe(fpath):
		return os.path.isfile(fpath) and os.access(fpath, os.X_OK)

	fpath, fname = os.path.split(name)
	if fpath and is_exe(name):
		return os.path.abspath(name)
	else:
		env = env or os.environ
		for path in env['PATH'].split(os.pathsep):
			path = path.strip('"')
			exe_file = os.path.join(path, name)
			if is_exe(exe_file):
				return os.path.abspath(exe_file)
	return None

def def_attrs(cls, **kw):
	"""
	Sets default attributes on a class instance

	:type cls: class
	:param cls: the class to update the given attributes in.
	:type kw: dict
	:param kw: dictionary of attributes names and values.
	"""
	for k, v in kw.items():
		if not hasattr(cls, k):
			setattr(cls, k, v)

def quote_define_name(s):
	"""
	Converts a string into an identifier suitable for C defines.

	:type  s: string
	:param s: String to convert
	:rtype: string
	:return: Identifier suitable for C defines
	"""
	fu = re.sub('[^a-zA-Z0-9]', '_', s)
	fu = re.sub('_+', '_', fu)
	fu = fu.upper()
	return fu

# shlex.quote didn't exist until python 3.3. Prior to that it was a non-documented
# function in pipes.
try:
	shell_quote = shlex.quote
except AttributeError:
	import pipes
	shell_quote = pipes.quote

def shell_escape(cmd):
	"""
	Escapes a command:
	['ls', '-l', 'arg space'] -> ls -l 'arg space'
	"""
	if isinstance(cmd, str):
		return cmd
	return ' '.join(shell_quote(x) for x in cmd)

def h_list(lst):
	"""
	Hashes lists of ordered data.

	Using hash(tup) for tuples would be much more efficient,
	but Python now enforces hash randomization

	:param lst: list to hash
	:type lst: list of strings
	:return: hash of the list
	"""
	return md5(repr(lst).encode()).digest()

if sys.hexversion < 0x3000000:
	def h_list_python2(lst):
		return md5(repr(lst)).digest()
	h_list_python2.__doc__ = h_list.__doc__
	h_list = h_list_python2

def h_fun(fun):
	"""
	Hash functions

	:param fun: function to hash
	:type  fun: function
	:return: hash of the function
	:rtype: string or bytes
	"""
	try:
		return fun.code
	except AttributeError:
		if isinstance(fun, functools.partial):
			code = list(fun.args)
			# The method items() provides a sequence of tuples where the first element
			# represents an optional argument of the partial function application
			#
			# The sorting result outcome will be consistent because:
			# 1. tuples are compared in order of their elements
			# 2. optional argument namess are unique
			code.extend(sorted(fun.keywords.items()))
			code.append(h_fun(fun.func))
			fun.code = h_list(code)
			return fun.code
		try:
			h = inspect.getsource(fun)
		except EnvironmentError:
			h = 'nocode'
		try:
			fun.code = h
		except AttributeError:
			pass
		return h

def h_cmd(ins):
	"""
	Hashes objects recursively

	:param ins: input object
	:type ins: string or list or tuple or function
	:rtype: string or bytes
	"""
	# this function is not meant to be particularly fast
	if isinstance(ins, str):
		# a command is either a string
		ret = ins
	elif isinstance(ins, list) or isinstance(ins, tuple):
		# or a list of functions/strings
		ret = str([h_cmd(x) for x in ins])
	else:
		# or just a python function
		ret = str(h_fun(ins))
	if sys.hexversion > 0x3000000:
		ret = ret.encode('latin-1', 'xmlcharrefreplace')
	return ret

reg_subst = re.compile(r"(\\\\)|(\$\$)|\$\{([^}]+)\}")
def subst_vars(expr, params):
	"""
	Replaces ${VAR} with the value of VAR taken from a dict or a config set::

		from waflib import Utils
		s = Utils.subst_vars('${PREFIX}/bin', env)

	:type  expr: string
	:param expr: String to perform substitution on
	:param params: Dictionary or config set to look up variable values.
	"""
	def repl_var(m):
		if m.group(1):
			return '\\'
		if m.group(2):
			return '$'
		try:
			# ConfigSet instances may contain lists
			return params.get_flat(m.group(3))
		except AttributeError:
			return params[m.group(3)]
		# if you get a TypeError, it means that 'expr' is not a string...
		# Utils.subst_vars(None, env)  will not work
	return reg_subst.sub(repl_var, expr)

def destos_to_binfmt(key):
	"""
	Returns the binary format based on the unversioned platform name,
	and defaults to ``elf`` if nothing is found.

	:param key: platform name
	:type  key: string
	:return: string representing the binary format
	"""
	if key == 'darwin':
		return 'mac-o'
	elif key in ('win32', 'cygwin', 'uwin', 'msys'):
		return 'pe'
	return 'elf'

def unversioned_sys_platform():
	"""
	Returns the unversioned platform name.
	Some Python platform names contain versions, that depend on
	the build environment, e.g. linux2, freebsd6, etc.
	This returns the name without the version number. Exceptions are
	os2 and win32, which are returned verbatim.

	:rtype: string
	:return: Unversioned platform name
	"""
	s = sys.platform
	if s.startswith('java'):
		# The real OS is hidden under the JVM.
		from java.lang import System
		s = System.getProperty('os.name')
		# see http://lopica.sourceforge.net/os.html for a list of possible values
		if s == 'Mac OS X':
			return 'darwin'
		elif s.startswith('Windows '):
			return 'win32'
		elif s == 'OS/2':
			return 'os2'
		elif s == 'HP-UX':
			return 'hp-ux'
		elif s in ('SunOS', 'Solaris'):
			return 'sunos'
		else: s = s.lower()

	# powerpc == darwin for our purposes
	if s == 'powerpc':
		return 'darwin'
	if s == 'win32' or s == 'os2':
		return s
	if s == 'cli' and os.name == 'nt':
		# ironpython is only on windows as far as we know
		return 'win32'
	return re.split(r'\d+$', s)[0]

def nada(*k, **kw):
	"""
	Does nothing

	:return: None
	"""
	pass

class Timer(object):
	"""
	Simple object for timing the execution of commands.
	Its string representation is the duration::

		from waflib.Utils import Timer
		timer = Timer()
		a_few_operations()
		s = str(timer)
	"""
	def __init__(self):
		self.start_time = self.now()

	def __str__(self):
		delta = self.now() - self.start_time
		if not isinstance(delta, datetime.timedelta):
			delta = datetime.timedelta(seconds=delta)
		days = delta.days
		hours, rem = divmod(delta.seconds, 3600)
		minutes, seconds = divmod(rem, 60)
		seconds += delta.microseconds * 1e-6
		result = ''
		if days:
			result += '%dd' % days
		if days or hours:
			result += '%dh' % hours
		if days or hours or minutes:
			result += '%dm' % minutes
		return '%s%.3fs' % (result, seconds)

	def now(self):
		return datetime.datetime.utcnow()

	if hasattr(time, 'perf_counter'):
		def now(self):
			return time.perf_counter()

def read_la_file(path):
	"""
	Reads property files, used by msvc.py

	:param path: file to read
	:type path: string
	"""
	sp = re.compile(r'^([^=]+)=\'(.*)\'$')
	dc = {}
	for line in readf(path).splitlines():
		try:
			_, left, right, _ = sp.split(line.strip())
			dc[left] = right
		except ValueError:
			pass
	return dc

def run_once(fun):
	"""
	Decorator: let a function cache its results, use like this::

		@run_once
		def foo(k):
			return 345*2343

	.. note:: in practice this can cause memory leaks, prefer a :py:class:`waflib.Utils.lru_cache`

	:param fun: function to execute
	:type fun: function
	:return: the return value of the function executed
	"""
	cache = {}
	def wrap(*k):
		try:
			return cache[k]
		except KeyError:
			ret = fun(*k)
			cache[k] = ret
			return ret
	wrap.__cache__ = cache
	wrap.__name__ = fun.__name__
	return wrap

def get_registry_app_path(key, filename):
	"""
	Returns the value of a registry key for an executable

	:type key: string
	:type filename: list of string
	"""
	if not winreg:
		return None
	try:
		result = winreg.QueryValue(key, "Software\\Microsoft\\Windows\\CurrentVersion\\App Paths\\%s.exe" % filena